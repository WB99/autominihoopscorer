{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "V9_zYZlrw-74",
        "Cbv2C_xSGaqX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Environment Setup"
      ],
      "metadata": {
        "id": "p8ONei7bv38R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6h2SC9aviUO",
        "outputId": "44fde2e2-7d7e-4e51-fe71-5bfa6855db8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "EgU2yzFnOYRt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Data"
      ],
      "metadata": {
        "id": "i3dllVqiOgPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting a fixed random seed for reproducibility\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Load datasets\n",
        "made_shots = pd.read_csv('/content/drive/MyDrive/iot ballballs/made_shots.csv')\n",
        "missed_shots = pd.read_csv('/content/drive/MyDrive/iot ballballs/missed_shots.csv')\n",
        "\n",
        "# Add labels\n",
        "made_shots['Label'] = 1\n",
        "missed_shots['Label'] = 0\n",
        "\n",
        "# Combine the datasets\n",
        "data = pd.concat([made_shots, missed_shots], axis=0)"
      ],
      "metadata": {
        "id": "plyGD6anOl3E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(made_shots.shape)\n",
        "print(missed_shots.shape)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p34H-jOjU_Tu",
        "outputId": "798949c9-6aea-4ca6-d578-9d5c12e3ba34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17600, 9)\n",
            "(17600, 9)\n",
            "(35200, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_and_prepare_sequences(df):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for shot_id in df['ShotID'].unique():\n",
        "        shot_data = df[df['ShotID'] == shot_id]\n",
        "\n",
        "        # Normalize the IMU data\n",
        "        normalized_sequence = (shot_data[['aX', 'aY', 'aZ', 'gX', 'gY', 'gZ']] + [4, 4, 4, 2000, 2000, 2000]) / [8, 8, 8, 4000, 4000, 4000]\n",
        "        sequences.append(normalized_sequence.values)\n",
        "        labels.append(shot_data['Label'].iloc[0])\n",
        "\n",
        "    return sequences, labels\n",
        "\n",
        "sequences, labels = normalize_and_prepare_sequences(data)"
      ],
      "metadata": {
        "id": "utt5CUytX143"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.asarray(sequences, dtype=\"object\").shape)\n",
        "print(np.asarray(labels, dtype=\"object\").shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfSJWG8VqtZ",
        "outputId": "fc1c0c0b-af58-44f4-85b1-65bf512d46ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 176, 6)\n",
            "(200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the sequences and labels together\n",
        "sequences_shuffled, labels_shuffled = shuffle(sequences, labels, random_state=SEED)\n",
        "\n",
        "# Pad sequences for consistent length\n",
        "X = pad_sequences(sequences_shuffled, dtype='float32', padding='post')\n",
        "print(X.shape)\n",
        "y = to_categorical(labels_shuffled)\n",
        "print(y.shape)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4-iXRyX6qT",
        "outputId": "3c90fb7e-5861-4015-b58d-dc8ab8996f83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 176, 6)\n",
            "(200, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Neural Network"
      ],
      "metadata": {
        "id": "IHQ9xW-kx9xH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM Single Layer"
      ],
      "metadata": {
        "id": "BTmuhIlkRXfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "timesteps = 176\n",
        "features = 6\n",
        "output_units = 2\n",
        "\n",
        "# Build the model\n",
        "inputs = keras.Input(shape=(timesteps, features), batch_size=1)\n",
        "x = keras.layers.LSTM(16)(inputs)\n",
        "outputs = keras.layers.Dense(output_units, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='acc')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=400, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvJvP-94Rf4z",
        "outputId": "7e479ef5-e60d-4438-f994-6af9bbc8588b",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "5/5 [==============================] - 5s 320ms/step - loss: 0.6933 - acc: 0.4938 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 2/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 3/400\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 4/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 5/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 6/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 7/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 8/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 9/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 10/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 11/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4750\n",
            "Epoch 12/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6928 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 13/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.4750\n",
            "Epoch 14/400\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 15/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 16/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.4750\n",
            "Epoch 17/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.6943 - acc: 0.4250 - val_loss: 0.6924 - val_acc: 0.6000\n",
            "Epoch 18/400\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 0.6929 - acc: 0.4938 - val_loss: 0.6926 - val_acc: 0.4750\n",
            "Epoch 19/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6929 - acc: 0.4563 - val_loss: 0.6927 - val_acc: 0.4750\n",
            "Epoch 20/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6928 - acc: 0.5375 - val_loss: 0.6926 - val_acc: 0.4750\n",
            "Epoch 21/400\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6926 - val_acc: 0.4500\n",
            "Epoch 22/400\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 23/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4750\n",
            "Epoch 24/400\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 25/400\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 26/400\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6940 - val_acc: 0.4750\n",
            "Epoch 27/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 28/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6928 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 29/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4750\n",
            "Epoch 30/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.4750\n",
            "Epoch 31/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 32/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.6928 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 33/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.6927 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.4500\n",
            "Epoch 34/400\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.6925 - acc: 0.5125 - val_loss: 0.6927 - val_acc: 0.4750\n",
            "Epoch 35/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.6925 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 36/400\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.6928 - acc: 0.5125 - val_loss: 0.6926 - val_acc: 0.4750\n",
            "Epoch 37/400\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.4750\n",
            "Epoch 38/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6927 - val_acc: 0.4750\n",
            "Epoch 39/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 40/400\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.6926 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 41/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 42/400\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4750\n",
            "Epoch 43/400\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 44/400\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.6924 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 45/400\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.4500\n",
            "Epoch 46/400\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6933 - acc: 0.4437 - val_loss: 0.6916 - val_acc: 0.6250\n",
            "Epoch 47/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.4750\n",
            "Epoch 48/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.6925 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4750\n",
            "Epoch 49/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6924 - acc: 0.5063 - val_loss: 0.6927 - val_acc: 0.4750\n",
            "Epoch 50/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 51/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6922 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 52/400\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.4750\n",
            "Epoch 53/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6938 - acc: 0.5125 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 54/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6923 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.4750\n",
            "Epoch 55/400\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6922 - acc: 0.5125 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 56/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6925 - acc: 0.5312 - val_loss: 0.6918 - val_acc: 0.5750\n",
            "Epoch 57/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6923 - acc: 0.5063 - val_loss: 0.6922 - val_acc: 0.4750\n",
            "Epoch 58/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.6926 - acc: 0.5063 - val_loss: 0.6929 - val_acc: 0.4750\n",
            "Epoch 59/400\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.6924 - acc: 0.5063 - val_loss: 0.6919 - val_acc: 0.4750\n",
            "Epoch 60/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6928 - acc: 0.4812 - val_loss: 0.6914 - val_acc: 0.6750\n",
            "Epoch 61/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.6922 - acc: 0.5750 - val_loss: 0.6913 - val_acc: 0.6750\n",
            "Epoch 62/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6944 - acc: 0.5063 - val_loss: 0.6910 - val_acc: 0.5750\n",
            "Epoch 63/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 64/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6921 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 65/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.6924 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 66/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6921 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 67/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6921 - acc: 0.5063 - val_loss: 0.6922 - val_acc: 0.4750\n",
            "Epoch 68/400\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.6923 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 69/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.6923 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4750\n",
            "Epoch 70/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.6919 - acc: 0.5063 - val_loss: 0.6920 - val_acc: 0.4750\n",
            "Epoch 71/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6919 - acc: 0.5063 - val_loss: 0.6920 - val_acc: 0.4750\n",
            "Epoch 72/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.6919 - acc: 0.5000 - val_loss: 0.6914 - val_acc: 0.4250\n",
            "Epoch 73/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6921 - acc: 0.5500 - val_loss: 0.6910 - val_acc: 0.6500\n",
            "Epoch 74/400\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.6923 - acc: 0.5188 - val_loss: 0.6917 - val_acc: 0.4750\n",
            "Epoch 75/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6918 - acc: 0.5000 - val_loss: 0.6914 - val_acc: 0.4750\n",
            "Epoch 76/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6951 - acc: 0.5000 - val_loss: 0.6935 - val_acc: 0.4750\n",
            "Epoch 77/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6918 - acc: 0.5063 - val_loss: 0.6918 - val_acc: 0.4750\n",
            "Epoch 78/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.6915 - acc: 0.5063 - val_loss: 0.6914 - val_acc: 0.4750\n",
            "Epoch 79/400\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.6918 - acc: 0.5125 - val_loss: 0.6906 - val_acc: 0.6750\n",
            "Epoch 80/400\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.6923 - acc: 0.5562 - val_loss: 0.6905 - val_acc: 0.6750\n",
            "Epoch 81/400\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.6918 - acc: 0.6062 - val_loss: 0.6911 - val_acc: 0.4500\n",
            "Epoch 82/400\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.6917 - acc: 0.4938 - val_loss: 0.6911 - val_acc: 0.4750\n",
            "Epoch 83/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.6915 - acc: 0.5063 - val_loss: 0.6918 - val_acc: 0.4750\n",
            "Epoch 84/400\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.6917 - acc: 0.5063 - val_loss: 0.6920 - val_acc: 0.4750\n",
            "Epoch 85/400\n",
            "5/5 [==============================] - 1s 221ms/step - loss: 0.6917 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 86/400\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.6923 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 87/400\n",
            "5/5 [==============================] - 1s 202ms/step - loss: 0.6926 - acc: 0.4938 - val_loss: 0.6902 - val_acc: 0.6750\n",
            "Epoch 88/400\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 0.6917 - acc: 0.5000 - val_loss: 0.6906 - val_acc: 0.4250\n",
            "Epoch 89/400\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 0.6923 - acc: 0.5375 - val_loss: 0.6898 - val_acc: 0.6750\n",
            "Epoch 90/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6925 - acc: 0.5375 - val_loss: 0.6900 - val_acc: 0.6750\n",
            "Epoch 91/400\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.6912 - acc: 0.5375 - val_loss: 0.6913 - val_acc: 0.4750\n",
            "Epoch 92/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6912 - acc: 0.5000 - val_loss: 0.6923 - val_acc: 0.4750\n",
            "Epoch 93/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.6913 - acc: 0.5063 - val_loss: 0.6924 - val_acc: 0.4750\n",
            "Epoch 94/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.6920 - acc: 0.4750 - val_loss: 0.6899 - val_acc: 0.6250\n",
            "Epoch 95/400\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.6911 - acc: 0.5688 - val_loss: 0.6897 - val_acc: 0.6250\n",
            "Epoch 96/400\n",
            "5/5 [==============================] - 0s 86ms/step - loss: 0.6908 - acc: 0.5875 - val_loss: 0.6901 - val_acc: 0.4750\n",
            "Epoch 97/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6908 - acc: 0.4938 - val_loss: 0.6898 - val_acc: 0.4250\n",
            "Epoch 98/400\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.6910 - acc: 0.4875 - val_loss: 0.6901 - val_acc: 0.4750\n",
            "Epoch 99/400\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.6910 - acc: 0.4625 - val_loss: 0.6894 - val_acc: 0.4250\n",
            "Epoch 100/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.6926 - acc: 0.5188 - val_loss: 0.6926 - val_acc: 0.4750\n",
            "Epoch 101/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.6921 - acc: 0.5063 - val_loss: 0.6913 - val_acc: 0.4750\n",
            "Epoch 102/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.6938 - acc: 0.4500 - val_loss: 0.6873 - val_acc: 0.5250\n",
            "Epoch 103/400\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.6911 - acc: 0.5125 - val_loss: 0.6876 - val_acc: 0.6500\n",
            "Epoch 104/400\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.6909 - acc: 0.5875 - val_loss: 0.6888 - val_acc: 0.4750\n",
            "Epoch 105/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.6903 - acc: 0.5000 - val_loss: 0.6913 - val_acc: 0.4750\n",
            "Epoch 106/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6905 - acc: 0.5125 - val_loss: 0.6906 - val_acc: 0.4750\n",
            "Epoch 107/400\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 0.6930 - acc: 0.4563 - val_loss: 0.6872 - val_acc: 0.7000\n",
            "Epoch 108/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6899 - acc: 0.6062 - val_loss: 0.6873 - val_acc: 0.6750\n",
            "Epoch 109/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6895 - acc: 0.6438 - val_loss: 0.6880 - val_acc: 0.4250\n",
            "Epoch 110/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.6900 - acc: 0.5000 - val_loss: 0.6906 - val_acc: 0.4750\n",
            "Epoch 111/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.6921 - acc: 0.5000 - val_loss: 0.6903 - val_acc: 0.4750\n",
            "Epoch 112/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.6875 - acc: 0.5000 - val_loss: 0.6853 - val_acc: 0.6750\n",
            "Epoch 113/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.6924 - acc: 0.5562 - val_loss: 0.6838 - val_acc: 0.5250\n",
            "Epoch 114/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.6896 - acc: 0.5437 - val_loss: 0.6844 - val_acc: 0.6000\n",
            "Epoch 115/400\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.6915 - acc: 0.5000 - val_loss: 0.6918 - val_acc: 0.4750\n",
            "Epoch 116/400\n",
            "5/5 [==============================] - 1s 123ms/step - loss: 0.6918 - acc: 0.4812 - val_loss: 0.6834 - val_acc: 0.6750\n",
            "Epoch 117/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.6890 - acc: 0.5875 - val_loss: 0.6819 - val_acc: 0.7000\n",
            "Epoch 118/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.6893 - acc: 0.4750 - val_loss: 0.6835 - val_acc: 0.4500\n",
            "Epoch 119/400\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.6860 - acc: 0.4688 - val_loss: 0.6794 - val_acc: 0.6250\n",
            "Epoch 120/400\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.6859 - acc: 0.4500 - val_loss: 0.6769 - val_acc: 0.6500\n",
            "Epoch 121/400\n",
            "5/5 [==============================] - 1s 122ms/step - loss: 0.6849 - acc: 0.5562 - val_loss: 0.6738 - val_acc: 0.7000\n",
            "Epoch 122/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.6873 - acc: 0.5938 - val_loss: 0.6713 - val_acc: 0.6750\n",
            "Epoch 123/400\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.6853 - acc: 0.6125 - val_loss: 0.6756 - val_acc: 0.6750\n",
            "Epoch 124/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6855 - acc: 0.4750 - val_loss: 0.6799 - val_acc: 0.4250\n",
            "Epoch 125/400\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.6865 - acc: 0.4812 - val_loss: 0.6819 - val_acc: 0.4500\n",
            "Epoch 126/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6850 - acc: 0.4750 - val_loss: 0.6779 - val_acc: 0.4750\n",
            "Epoch 127/400\n",
            "5/5 [==============================] - 1s 179ms/step - loss: 0.6836 - acc: 0.5375 - val_loss: 0.6748 - val_acc: 0.7000\n",
            "Epoch 128/400\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.6876 - acc: 0.5813 - val_loss: 0.6726 - val_acc: 0.7000\n",
            "Epoch 129/400\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.6841 - acc: 0.5375 - val_loss: 0.6876 - val_acc: 0.4750\n",
            "Epoch 130/400\n",
            "5/5 [==============================] - 1s 117ms/step - loss: 0.6833 - acc: 0.5063 - val_loss: 0.6678 - val_acc: 0.6500\n",
            "Epoch 131/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.6697 - acc: 0.6000 - val_loss: 0.6308 - val_acc: 0.6250\n",
            "Epoch 132/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.6680 - acc: 0.5562 - val_loss: 0.6737 - val_acc: 0.7000\n",
            "Epoch 133/400\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.6693 - acc: 0.6062 - val_loss: 0.6427 - val_acc: 0.7500\n",
            "Epoch 134/400\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.6494 - acc: 0.5813 - val_loss: 0.6002 - val_acc: 0.6750\n",
            "Epoch 135/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.7046 - acc: 0.4938 - val_loss: 0.7477 - val_acc: 0.4000\n",
            "Epoch 136/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.7061 - acc: 0.4938 - val_loss: 0.6673 - val_acc: 0.7000\n",
            "Epoch 137/400\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.6849 - acc: 0.5750 - val_loss: 0.6757 - val_acc: 0.7000\n",
            "Epoch 138/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.6867 - acc: 0.6313 - val_loss: 0.6814 - val_acc: 0.6000\n",
            "Epoch 139/400\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.6859 - acc: 0.4875 - val_loss: 0.6846 - val_acc: 0.4500\n",
            "Epoch 140/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.6868 - acc: 0.4812 - val_loss: 0.6838 - val_acc: 0.4250\n",
            "Epoch 141/400\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.6872 - acc: 0.4875 - val_loss: 0.6848 - val_acc: 0.4500\n",
            "Epoch 142/400\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.6864 - acc: 0.4875 - val_loss: 0.6837 - val_acc: 0.4250\n",
            "Epoch 143/400\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 0.6864 - acc: 0.4812 - val_loss: 0.6829 - val_acc: 0.5500\n",
            "Epoch 144/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.6863 - acc: 0.5250 - val_loss: 0.6825 - val_acc: 0.6000\n",
            "Epoch 145/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.6857 - acc: 0.5437 - val_loss: 0.6817 - val_acc: 0.6750\n",
            "Epoch 146/400\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.6865 - acc: 0.6625 - val_loss: 0.6803 - val_acc: 0.7000\n",
            "Epoch 147/400\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.6859 - acc: 0.6375 - val_loss: 0.6800 - val_acc: 0.7000\n",
            "Epoch 148/400\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.6859 - acc: 0.5938 - val_loss: 0.6813 - val_acc: 0.6000\n",
            "Epoch 149/400\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.6851 - acc: 0.5500 - val_loss: 0.6808 - val_acc: 0.6000\n",
            "Epoch 150/400\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.6850 - acc: 0.5188 - val_loss: 0.6801 - val_acc: 0.6000\n",
            "Epoch 151/400\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.6845 - acc: 0.5437 - val_loss: 0.6800 - val_acc: 0.6000\n",
            "Epoch 152/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6848 - acc: 0.5750 - val_loss: 0.6790 - val_acc: 0.6500\n",
            "Epoch 153/400\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.6853 - acc: 0.4625 - val_loss: 0.6802 - val_acc: 0.4000\n",
            "Epoch 154/400\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 0.6836 - acc: 0.4688 - val_loss: 0.6785 - val_acc: 0.6000\n",
            "Epoch 155/400\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.6836 - acc: 0.5688 - val_loss: 0.6764 - val_acc: 0.6750\n",
            "Epoch 156/400\n",
            "5/5 [==============================] - 0s 47ms/step - loss: 0.6830 - acc: 0.6500 - val_loss: 0.6754 - val_acc: 0.6750\n",
            "Epoch 157/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.6826 - acc: 0.6562 - val_loss: 0.6751 - val_acc: 0.6750\n",
            "Epoch 158/400\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.6824 - acc: 0.6500 - val_loss: 0.6747 - val_acc: 0.6750\n",
            "Epoch 159/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.6818 - acc: 0.5375 - val_loss: 0.6746 - val_acc: 0.6500\n",
            "Epoch 160/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6813 - acc: 0.5312 - val_loss: 0.6733 - val_acc: 0.6000\n",
            "Epoch 161/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.6810 - acc: 0.5437 - val_loss: 0.6726 - val_acc: 0.6750\n",
            "Epoch 162/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6817 - acc: 0.4812 - val_loss: 0.6727 - val_acc: 0.4250\n",
            "Epoch 163/400\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.6800 - acc: 0.5875 - val_loss: 0.6679 - val_acc: 0.7000\n",
            "Epoch 164/400\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 0.6803 - acc: 0.6313 - val_loss: 0.6662 - val_acc: 0.7000\n",
            "Epoch 165/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.6805 - acc: 0.5500 - val_loss: 0.6710 - val_acc: 0.4000\n",
            "Epoch 166/400\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.6766 - acc: 0.4625 - val_loss: 0.6657 - val_acc: 0.6500\n",
            "Epoch 167/400\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.6724 - acc: 0.6250 - val_loss: 0.6611 - val_acc: 0.6500\n",
            "Epoch 168/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6712 - acc: 0.6438 - val_loss: 0.6508 - val_acc: 0.7000\n",
            "Epoch 169/400\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.6642 - acc: 0.5063 - val_loss: 0.6358 - val_acc: 0.7500\n",
            "Epoch 170/400\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.6569 - acc: 0.6250 - val_loss: 0.5804 - val_acc: 0.8000\n",
            "Epoch 171/400\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.6384 - acc: 0.6313 - val_loss: 0.6564 - val_acc: 0.6000\n",
            "Epoch 172/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.7308 - acc: 0.5125 - val_loss: 0.5397 - val_acc: 0.8000\n",
            "Epoch 173/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.6806 - acc: 0.5875 - val_loss: 0.6083 - val_acc: 0.7000\n",
            "Epoch 174/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.6601 - acc: 0.6187 - val_loss: 0.6395 - val_acc: 0.6750\n",
            "Epoch 175/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.6417 - acc: 0.6375 - val_loss: 0.6382 - val_acc: 0.6500\n",
            "Epoch 176/400\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.6511 - acc: 0.6000 - val_loss: 0.5857 - val_acc: 0.7250\n",
            "Epoch 177/400\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.6285 - acc: 0.6812 - val_loss: 0.5454 - val_acc: 0.8000\n",
            "Epoch 178/400\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.5855 - acc: 0.7125 - val_loss: 0.5394 - val_acc: 0.7750\n",
            "Epoch 179/400\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.5690 - acc: 0.6938 - val_loss: 0.5277 - val_acc: 0.7250\n",
            "Epoch 180/400\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.6311 - acc: 0.6500 - val_loss: 0.5383 - val_acc: 0.7500\n",
            "Epoch 181/400\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 0.5972 - acc: 0.6750 - val_loss: 0.5544 - val_acc: 0.7500\n",
            "Epoch 182/400\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 0.6359 - acc: 0.6625 - val_loss: 0.5258 - val_acc: 0.7750\n",
            "Epoch 183/400\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.5845 - acc: 0.6687 - val_loss: 0.5160 - val_acc: 0.7750\n",
            "Epoch 184/400\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.5811 - acc: 0.7000 - val_loss: 0.5138 - val_acc: 0.7750\n",
            "Epoch 185/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.5820 - acc: 0.6812 - val_loss: 0.5122 - val_acc: 0.7750\n",
            "Epoch 186/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5666 - acc: 0.7437 - val_loss: 0.5052 - val_acc: 0.7750\n",
            "Epoch 187/400\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.5418 - acc: 0.7375 - val_loss: 0.5174 - val_acc: 0.7750\n",
            "Epoch 188/400\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.5347 - acc: 0.7500 - val_loss: 0.4953 - val_acc: 0.8000\n",
            "Epoch 189/400\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.5410 - acc: 0.7125 - val_loss: 0.4882 - val_acc: 0.8000\n",
            "Epoch 190/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.5367 - acc: 0.7500 - val_loss: 0.5449 - val_acc: 0.7500\n",
            "Epoch 191/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5380 - acc: 0.7188 - val_loss: 0.4897 - val_acc: 0.7750\n",
            "Epoch 192/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.5191 - acc: 0.7437 - val_loss: 0.5218 - val_acc: 0.7250\n",
            "Epoch 193/400\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.5200 - acc: 0.7750 - val_loss: 0.4720 - val_acc: 0.8250\n",
            "Epoch 194/400\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.5421 - acc: 0.7250 - val_loss: 0.5952 - val_acc: 0.6500\n",
            "Epoch 195/400\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.5221 - acc: 0.7375 - val_loss: 0.4889 - val_acc: 0.8250\n",
            "Epoch 196/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5665 - acc: 0.7000 - val_loss: 0.5292 - val_acc: 0.7750\n",
            "Epoch 197/400\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.5514 - acc: 0.7000 - val_loss: 0.4866 - val_acc: 0.8000\n",
            "Epoch 198/400\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.5350 - acc: 0.7375 - val_loss: 0.5023 - val_acc: 0.7500\n",
            "Epoch 199/400\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.5024 - acc: 0.7500 - val_loss: 0.4598 - val_acc: 0.8250\n",
            "Epoch 200/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.5341 - acc: 0.7375 - val_loss: 0.4776 - val_acc: 0.8000\n",
            "Epoch 201/400\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.5104 - acc: 0.7625 - val_loss: 0.4965 - val_acc: 0.8000\n",
            "Epoch 202/400\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.5164 - acc: 0.7375 - val_loss: 0.4678 - val_acc: 0.8000\n",
            "Epoch 203/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.5068 - acc: 0.7375 - val_loss: 0.4608 - val_acc: 0.8000\n",
            "Epoch 204/400\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 0.4961 - acc: 0.7812 - val_loss: 0.4991 - val_acc: 0.7500\n",
            "Epoch 205/400\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 0.4832 - acc: 0.7937 - val_loss: 0.4556 - val_acc: 0.8250\n",
            "Epoch 206/400\n",
            "5/5 [==============================] - 1s 116ms/step - loss: 0.5074 - acc: 0.7563 - val_loss: 0.5854 - val_acc: 0.6750\n",
            "Epoch 207/400\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 0.4812 - acc: 0.7750 - val_loss: 0.4508 - val_acc: 0.8250\n",
            "Epoch 208/400\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.5231 - acc: 0.7375 - val_loss: 0.4776 - val_acc: 0.7750\n",
            "Epoch 209/400\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.5186 - acc: 0.7625 - val_loss: 0.4808 - val_acc: 0.8000\n",
            "Epoch 210/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.5073 - acc: 0.7500 - val_loss: 0.5211 - val_acc: 0.7500\n",
            "Epoch 211/400\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.5088 - acc: 0.7375 - val_loss: 0.4772 - val_acc: 0.7750\n",
            "Epoch 212/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4858 - acc: 0.7750 - val_loss: 0.4605 - val_acc: 0.8000\n",
            "Epoch 213/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.4962 - acc: 0.7563 - val_loss: 0.4701 - val_acc: 0.7750\n",
            "Epoch 214/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4854 - acc: 0.7937 - val_loss: 0.4542 - val_acc: 0.8000\n",
            "Epoch 215/400\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.4925 - acc: 0.7437 - val_loss: 0.5024 - val_acc: 0.8000\n",
            "Epoch 216/400\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 0.5099 - acc: 0.7312 - val_loss: 0.4969 - val_acc: 0.8000\n",
            "Epoch 217/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.4903 - acc: 0.7563 - val_loss: 0.5535 - val_acc: 0.7250\n",
            "Epoch 218/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.4932 - acc: 0.7688 - val_loss: 0.4649 - val_acc: 0.7750\n",
            "Epoch 219/400\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.5004 - acc: 0.7500 - val_loss: 0.5178 - val_acc: 0.8000\n",
            "Epoch 220/400\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.5073 - acc: 0.7375 - val_loss: 0.4895 - val_acc: 0.8000\n",
            "Epoch 221/400\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.4941 - acc: 0.7688 - val_loss: 0.5444 - val_acc: 0.7250\n",
            "Epoch 222/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.4681 - acc: 0.7688 - val_loss: 0.4634 - val_acc: 0.7750\n",
            "Epoch 223/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4813 - acc: 0.7437 - val_loss: 0.5291 - val_acc: 0.7500\n",
            "Epoch 224/400\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.4987 - acc: 0.7500 - val_loss: 0.4407 - val_acc: 0.8250\n",
            "Epoch 225/400\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.4602 - acc: 0.7812 - val_loss: 0.4454 - val_acc: 0.8250\n",
            "Epoch 226/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4684 - acc: 0.7688 - val_loss: 0.5281 - val_acc: 0.7250\n",
            "Epoch 227/400\n",
            "5/5 [==============================] - 1s 142ms/step - loss: 0.4665 - acc: 0.7750 - val_loss: 0.4545 - val_acc: 0.8000\n",
            "Epoch 228/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.4547 - acc: 0.7750 - val_loss: 0.4734 - val_acc: 0.7750\n",
            "Epoch 229/400\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.4512 - acc: 0.7563 - val_loss: 0.4956 - val_acc: 0.7500\n",
            "Epoch 230/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.4464 - acc: 0.7937 - val_loss: 0.4607 - val_acc: 0.7750\n",
            "Epoch 231/400\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.4638 - acc: 0.7937 - val_loss: 0.6640 - val_acc: 0.5750\n",
            "Epoch 232/400\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.5202 - acc: 0.7312 - val_loss: 0.5086 - val_acc: 0.7500\n",
            "Epoch 233/400\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.5695 - acc: 0.7312 - val_loss: 0.4676 - val_acc: 0.8000\n",
            "Epoch 234/400\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 0.4729 - acc: 0.7563 - val_loss: 0.5211 - val_acc: 0.7500\n",
            "Epoch 235/400\n",
            "5/5 [==============================] - 1s 221ms/step - loss: 0.4545 - acc: 0.7937 - val_loss: 0.4835 - val_acc: 0.7750\n",
            "Epoch 236/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.4510 - acc: 0.7875 - val_loss: 0.5151 - val_acc: 0.7750\n",
            "Epoch 237/400\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.4785 - acc: 0.7625 - val_loss: 0.4306 - val_acc: 0.8250\n",
            "Epoch 238/400\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.4340 - acc: 0.8188 - val_loss: 0.5034 - val_acc: 0.7750\n",
            "Epoch 239/400\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 0.4561 - acc: 0.7812 - val_loss: 0.4861 - val_acc: 0.8000\n",
            "Epoch 240/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.4601 - acc: 0.7625 - val_loss: 0.4709 - val_acc: 0.8000\n",
            "Epoch 241/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.5111 - acc: 0.7437 - val_loss: 0.4639 - val_acc: 0.8000\n",
            "Epoch 242/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.4812 - acc: 0.7625 - val_loss: 0.4741 - val_acc: 0.7750\n",
            "Epoch 243/400\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.4851 - acc: 0.7688 - val_loss: 0.6085 - val_acc: 0.7000\n",
            "Epoch 244/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.5256 - acc: 0.7688 - val_loss: 0.5158 - val_acc: 0.7500\n",
            "Epoch 245/400\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.5787 - acc: 0.7375 - val_loss: 0.4737 - val_acc: 0.7500\n",
            "Epoch 246/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4966 - acc: 0.7750 - val_loss: 0.5549 - val_acc: 0.7250\n",
            "Epoch 247/400\n",
            "5/5 [==============================] - 0s 108ms/step - loss: 0.4716 - acc: 0.8188 - val_loss: 0.4592 - val_acc: 0.8000\n",
            "Epoch 248/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.4520 - acc: 0.7812 - val_loss: 0.5017 - val_acc: 0.7750\n",
            "Epoch 249/400\n",
            "5/5 [==============================] - 1s 122ms/step - loss: 0.4649 - acc: 0.7812 - val_loss: 0.4796 - val_acc: 0.8000\n",
            "Epoch 250/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.4643 - acc: 0.7688 - val_loss: 0.4516 - val_acc: 0.8250\n",
            "Epoch 251/400\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.4409 - acc: 0.7750 - val_loss: 0.5165 - val_acc: 0.7500\n",
            "Epoch 252/400\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.4348 - acc: 0.7875 - val_loss: 0.4536 - val_acc: 0.8000\n",
            "Epoch 253/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.4271 - acc: 0.8000 - val_loss: 0.5490 - val_acc: 0.7250\n",
            "Epoch 254/400\n",
            "5/5 [==============================] - 1s 98ms/step - loss: 0.4556 - acc: 0.7937 - val_loss: 0.4957 - val_acc: 0.7750\n",
            "Epoch 255/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.4392 - acc: 0.8000 - val_loss: 0.5032 - val_acc: 0.7750\n",
            "Epoch 256/400\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 0.4305 - acc: 0.7812 - val_loss: 0.4771 - val_acc: 0.8000\n",
            "Epoch 257/400\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 0.4618 - acc: 0.7812 - val_loss: 0.4851 - val_acc: 0.8000\n",
            "Epoch 258/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.4585 - acc: 0.7625 - val_loss: 0.5102 - val_acc: 0.7750\n",
            "Epoch 259/400\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.4472 - acc: 0.7812 - val_loss: 0.5030 - val_acc: 0.7500\n",
            "Epoch 260/400\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.4311 - acc: 0.7937 - val_loss: 0.4833 - val_acc: 0.7750\n",
            "Epoch 261/400\n",
            "5/5 [==============================] - 1s 116ms/step - loss: 0.4503 - acc: 0.7875 - val_loss: 0.4573 - val_acc: 0.8000\n",
            "Epoch 262/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4590 - acc: 0.7688 - val_loss: 0.5103 - val_acc: 0.7500\n",
            "Epoch 263/400\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 0.4221 - acc: 0.8125 - val_loss: 0.4543 - val_acc: 0.7750\n",
            "Epoch 264/400\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 0.4182 - acc: 0.8062 - val_loss: 0.4681 - val_acc: 0.8000\n",
            "Epoch 265/400\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.4191 - acc: 0.7812 - val_loss: 0.4860 - val_acc: 0.7750\n",
            "Epoch 266/400\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.4134 - acc: 0.8313 - val_loss: 0.4708 - val_acc: 0.7750\n",
            "Epoch 267/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.4137 - acc: 0.8000 - val_loss: 0.5257 - val_acc: 0.7750\n",
            "Epoch 268/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.4098 - acc: 0.8000 - val_loss: 0.4528 - val_acc: 0.8000\n",
            "Epoch 269/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4692 - acc: 0.7625 - val_loss: 0.5398 - val_acc: 0.7750\n",
            "Epoch 270/400\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.4867 - acc: 0.7563 - val_loss: 0.4841 - val_acc: 0.7750\n",
            "Epoch 271/400\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.5547 - acc: 0.7437 - val_loss: 0.4431 - val_acc: 0.8250\n",
            "Epoch 272/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4591 - acc: 0.7812 - val_loss: 0.5612 - val_acc: 0.7250\n",
            "Epoch 273/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4987 - acc: 0.7375 - val_loss: 0.4924 - val_acc: 0.8000\n",
            "Epoch 274/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4642 - acc: 0.7688 - val_loss: 0.4818 - val_acc: 0.8000\n",
            "Epoch 275/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4211 - acc: 0.8125 - val_loss: 0.4832 - val_acc: 0.7500\n",
            "Epoch 276/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4186 - acc: 0.7812 - val_loss: 0.5838 - val_acc: 0.7250\n",
            "Epoch 277/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4831 - acc: 0.7937 - val_loss: 0.4806 - val_acc: 0.8000\n",
            "Epoch 278/400\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.4306 - acc: 0.7750 - val_loss: 0.5285 - val_acc: 0.7250\n",
            "Epoch 279/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.4257 - acc: 0.8000 - val_loss: 0.4892 - val_acc: 0.7500\n",
            "Epoch 280/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4010 - acc: 0.8000 - val_loss: 0.5176 - val_acc: 0.7500\n",
            "Epoch 281/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4285 - acc: 0.8062 - val_loss: 0.4826 - val_acc: 0.8000\n",
            "Epoch 282/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4340 - acc: 0.7688 - val_loss: 0.4840 - val_acc: 0.7750\n",
            "Epoch 283/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4083 - acc: 0.8250 - val_loss: 0.4598 - val_acc: 0.8000\n",
            "Epoch 284/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.4067 - acc: 0.8000 - val_loss: 0.5631 - val_acc: 0.7250\n",
            "Epoch 285/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.4196 - acc: 0.8062 - val_loss: 0.5010 - val_acc: 0.7750\n",
            "Epoch 286/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.4129 - acc: 0.7875 - val_loss: 0.5433 - val_acc: 0.7500\n",
            "Epoch 287/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.4042 - acc: 0.8125 - val_loss: 0.4898 - val_acc: 0.7750\n",
            "Epoch 288/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.3974 - acc: 0.8125 - val_loss: 0.4947 - val_acc: 0.7750\n",
            "Epoch 289/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4531 - acc: 0.7563 - val_loss: 0.5341 - val_acc: 0.7500\n",
            "Epoch 290/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.4240 - acc: 0.8250 - val_loss: 0.4614 - val_acc: 0.7750\n",
            "Epoch 291/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.4715 - acc: 0.7500 - val_loss: 0.6025 - val_acc: 0.7000\n",
            "Epoch 292/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5584 - acc: 0.7437 - val_loss: 0.5326 - val_acc: 0.7250\n",
            "Epoch 293/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.5550 - acc: 0.7625 - val_loss: 0.4893 - val_acc: 0.8000\n",
            "Epoch 294/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.4677 - acc: 0.7625 - val_loss: 0.5351 - val_acc: 0.7500\n",
            "Epoch 295/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.4873 - acc: 0.7500 - val_loss: 0.4413 - val_acc: 0.8250\n",
            "Epoch 296/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.4899 - acc: 0.7500 - val_loss: 0.6463 - val_acc: 0.6500\n",
            "Epoch 297/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.5238 - acc: 0.7312 - val_loss: 0.4741 - val_acc: 0.8000\n",
            "Epoch 298/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.5519 - acc: 0.7563 - val_loss: 0.4894 - val_acc: 0.8000\n",
            "Epoch 299/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4474 - acc: 0.8062 - val_loss: 0.4992 - val_acc: 0.7250\n",
            "Epoch 300/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4507 - acc: 0.7937 - val_loss: 0.5418 - val_acc: 0.7250\n",
            "Epoch 301/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4248 - acc: 0.8062 - val_loss: 0.4768 - val_acc: 0.8000\n",
            "Epoch 302/400\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.4449 - acc: 0.7812 - val_loss: 0.5130 - val_acc: 0.7750\n",
            "Epoch 303/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.4440 - acc: 0.7812 - val_loss: 0.4496 - val_acc: 0.8000\n",
            "Epoch 304/400\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.4359 - acc: 0.7875 - val_loss: 0.5323 - val_acc: 0.7250\n",
            "Epoch 305/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.4313 - acc: 0.8188 - val_loss: 0.4809 - val_acc: 0.7750\n",
            "Epoch 306/400\n",
            "5/5 [==============================] - 1s 122ms/step - loss: 0.4186 - acc: 0.7937 - val_loss: 0.4723 - val_acc: 0.7750\n",
            "Epoch 307/400\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.4001 - acc: 0.8062 - val_loss: 0.5539 - val_acc: 0.7250\n",
            "Epoch 308/400\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 0.4214 - acc: 0.8000 - val_loss: 0.4385 - val_acc: 0.8250\n",
            "Epoch 309/400\n",
            "5/5 [==============================] - 1s 120ms/step - loss: 0.4428 - acc: 0.7688 - val_loss: 0.4737 - val_acc: 0.8000\n",
            "Epoch 310/400\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.4394 - acc: 0.7750 - val_loss: 0.4598 - val_acc: 0.8250\n",
            "Epoch 311/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4311 - acc: 0.7937 - val_loss: 0.5671 - val_acc: 0.7250\n",
            "Epoch 312/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.4181 - acc: 0.8188 - val_loss: 0.4585 - val_acc: 0.8000\n",
            "Epoch 313/400\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.4176 - acc: 0.8062 - val_loss: 0.4999 - val_acc: 0.7500\n",
            "Epoch 314/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.3975 - acc: 0.8000 - val_loss: 0.4842 - val_acc: 0.7750\n",
            "Epoch 315/400\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.3980 - acc: 0.8188 - val_loss: 0.4516 - val_acc: 0.8000\n",
            "Epoch 316/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.3891 - acc: 0.8125 - val_loss: 0.4619 - val_acc: 0.8000\n",
            "Epoch 317/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.3863 - acc: 0.8313 - val_loss: 0.5178 - val_acc: 0.7500\n",
            "Epoch 318/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.4006 - acc: 0.7937 - val_loss: 0.4809 - val_acc: 0.7750\n",
            "Epoch 319/400\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.3855 - acc: 0.8125 - val_loss: 0.5013 - val_acc: 0.7750\n",
            "Epoch 320/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.3915 - acc: 0.8125 - val_loss: 0.5113 - val_acc: 0.7750\n",
            "Epoch 321/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3802 - acc: 0.8188 - val_loss: 0.4978 - val_acc: 0.7500\n",
            "Epoch 322/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3978 - acc: 0.8125 - val_loss: 0.5131 - val_acc: 0.7500\n",
            "Epoch 323/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.3843 - acc: 0.8125 - val_loss: 0.4528 - val_acc: 0.7750\n",
            "Epoch 324/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4395 - acc: 0.8250 - val_loss: 0.5350 - val_acc: 0.7500\n",
            "Epoch 325/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.4078 - acc: 0.8000 - val_loss: 0.5014 - val_acc: 0.7750\n",
            "Epoch 326/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.4049 - acc: 0.8062 - val_loss: 0.5629 - val_acc: 0.7250\n",
            "Epoch 327/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.4341 - acc: 0.8000 - val_loss: 0.5340 - val_acc: 0.7250\n",
            "Epoch 328/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.3916 - acc: 0.8000 - val_loss: 0.4924 - val_acc: 0.7750\n",
            "Epoch 329/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3907 - acc: 0.8062 - val_loss: 0.4919 - val_acc: 0.7750\n",
            "Epoch 330/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.4123 - acc: 0.8438 - val_loss: 0.4899 - val_acc: 0.8000\n",
            "Epoch 331/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3862 - acc: 0.8062 - val_loss: 0.5598 - val_acc: 0.7250\n",
            "Epoch 332/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4214 - acc: 0.8000 - val_loss: 0.5143 - val_acc: 0.7750\n",
            "Epoch 333/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4138 - acc: 0.7812 - val_loss: 0.5108 - val_acc: 0.7500\n",
            "Epoch 334/400\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.3787 - acc: 0.8313 - val_loss: 0.5180 - val_acc: 0.7500\n",
            "Epoch 335/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.3827 - acc: 0.8438 - val_loss: 0.5198 - val_acc: 0.7750\n",
            "Epoch 336/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.3785 - acc: 0.8500 - val_loss: 0.5077 - val_acc: 0.7750\n",
            "Epoch 337/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3716 - acc: 0.8500 - val_loss: 0.5145 - val_acc: 0.7750\n",
            "Epoch 338/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3619 - acc: 0.8313 - val_loss: 0.5483 - val_acc: 0.7250\n",
            "Epoch 339/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.3697 - acc: 0.8438 - val_loss: 0.4883 - val_acc: 0.7500\n",
            "Epoch 340/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3727 - acc: 0.8375 - val_loss: 0.5918 - val_acc: 0.7500\n",
            "Epoch 341/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.4443 - acc: 0.7937 - val_loss: 0.4673 - val_acc: 0.8250\n",
            "Epoch 342/400\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.4052 - acc: 0.8125 - val_loss: 0.5332 - val_acc: 0.7750\n",
            "Epoch 343/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.4256 - acc: 0.8125 - val_loss: 0.4749 - val_acc: 0.8250\n",
            "Epoch 344/400\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 0.4206 - acc: 0.8313 - val_loss: 0.5095 - val_acc: 0.7750\n",
            "Epoch 345/400\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.4012 - acc: 0.7875 - val_loss: 0.5011 - val_acc: 0.7750\n",
            "Epoch 346/400\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 0.4260 - acc: 0.8438 - val_loss: 0.5318 - val_acc: 0.7500\n",
            "Epoch 347/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.3981 - acc: 0.8250 - val_loss: 0.5188 - val_acc: 0.7750\n",
            "Epoch 348/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.4226 - acc: 0.7875 - val_loss: 0.5254 - val_acc: 0.7750\n",
            "Epoch 349/400\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.4460 - acc: 0.7937 - val_loss: 0.5202 - val_acc: 0.7500\n",
            "Epoch 350/400\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 0.3892 - acc: 0.8188 - val_loss: 0.5288 - val_acc: 0.7500\n",
            "Epoch 351/400\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.3778 - acc: 0.8375 - val_loss: 0.4682 - val_acc: 0.7750\n",
            "Epoch 352/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.3947 - acc: 0.8125 - val_loss: 0.5189 - val_acc: 0.7500\n",
            "Epoch 353/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.3950 - acc: 0.8375 - val_loss: 0.4894 - val_acc: 0.8000\n",
            "Epoch 354/400\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.3960 - acc: 0.8188 - val_loss: 0.6742 - val_acc: 0.6750\n",
            "Epoch 355/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4395 - acc: 0.7688 - val_loss: 0.4776 - val_acc: 0.8000\n",
            "Epoch 356/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.4306 - acc: 0.8188 - val_loss: 0.5078 - val_acc: 0.7750\n",
            "Epoch 357/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.4054 - acc: 0.8125 - val_loss: 0.4927 - val_acc: 0.7750\n",
            "Epoch 358/400\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.3617 - acc: 0.8375 - val_loss: 0.5179 - val_acc: 0.7750\n",
            "Epoch 359/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.4056 - acc: 0.8375 - val_loss: 0.4918 - val_acc: 0.8000\n",
            "Epoch 360/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3800 - acc: 0.8125 - val_loss: 0.5017 - val_acc: 0.7750\n",
            "Epoch 361/400\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.3866 - acc: 0.8188 - val_loss: 0.5094 - val_acc: 0.7500\n",
            "Epoch 362/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3716 - acc: 0.8375 - val_loss: 0.5167 - val_acc: 0.7750\n",
            "Epoch 363/400\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.3663 - acc: 0.8375 - val_loss: 0.5100 - val_acc: 0.7500\n",
            "Epoch 364/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3641 - acc: 0.8562 - val_loss: 0.4570 - val_acc: 0.8250\n",
            "Epoch 365/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.3799 - acc: 0.8313 - val_loss: 0.5369 - val_acc: 0.7750\n",
            "Epoch 366/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3498 - acc: 0.8500 - val_loss: 0.4594 - val_acc: 0.8250\n",
            "Epoch 367/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3697 - acc: 0.8188 - val_loss: 0.5530 - val_acc: 0.8000\n",
            "Epoch 368/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3628 - acc: 0.8313 - val_loss: 0.4665 - val_acc: 0.8000\n",
            "Epoch 369/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.3721 - acc: 0.8313 - val_loss: 0.5183 - val_acc: 0.7750\n",
            "Epoch 370/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3604 - acc: 0.8375 - val_loss: 0.5471 - val_acc: 0.7250\n",
            "Epoch 371/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3612 - acc: 0.8313 - val_loss: 0.4851 - val_acc: 0.7500\n",
            "Epoch 372/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3594 - acc: 0.8438 - val_loss: 0.5223 - val_acc: 0.7500\n",
            "Epoch 373/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3603 - acc: 0.8438 - val_loss: 0.5463 - val_acc: 0.7250\n",
            "Epoch 374/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.3519 - acc: 0.8562 - val_loss: 0.4780 - val_acc: 0.7750\n",
            "Epoch 375/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.3757 - acc: 0.8313 - val_loss: 0.5342 - val_acc: 0.7250\n",
            "Epoch 376/400\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.4257 - acc: 0.7937 - val_loss: 0.5175 - val_acc: 0.8000\n",
            "Epoch 377/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.4300 - acc: 0.8062 - val_loss: 0.5934 - val_acc: 0.7000\n",
            "Epoch 378/400\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.4226 - acc: 0.7875 - val_loss: 0.5334 - val_acc: 0.7000\n",
            "Epoch 379/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.4117 - acc: 0.8000 - val_loss: 0.5799 - val_acc: 0.7250\n",
            "Epoch 380/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.4246 - acc: 0.7937 - val_loss: 0.5987 - val_acc: 0.7250\n",
            "Epoch 381/400\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.4326 - acc: 0.7875 - val_loss: 0.4951 - val_acc: 0.8000\n",
            "Epoch 382/400\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.4183 - acc: 0.8062 - val_loss: 0.5679 - val_acc: 0.7750\n",
            "Epoch 383/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.4945 - acc: 0.7937 - val_loss: 0.5097 - val_acc: 0.7750\n",
            "Epoch 384/400\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.4614 - acc: 0.8062 - val_loss: 0.4610 - val_acc: 0.8000\n",
            "Epoch 385/400\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3894 - acc: 0.8250 - val_loss: 0.5587 - val_acc: 0.7500\n",
            "Epoch 386/400\n",
            "5/5 [==============================] - 0s 49ms/step - loss: 0.3721 - acc: 0.8562 - val_loss: 0.4868 - val_acc: 0.7500\n",
            "Epoch 387/400\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3764 - acc: 0.8313 - val_loss: 0.5000 - val_acc: 0.7750\n",
            "Epoch 388/400\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3706 - acc: 0.8250 - val_loss: 0.5225 - val_acc: 0.7500\n",
            "Epoch 389/400\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.3576 - acc: 0.8375 - val_loss: 0.4903 - val_acc: 0.8000\n",
            "Epoch 390/400\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.4419 - acc: 0.7875 - val_loss: 0.5700 - val_acc: 0.7750\n",
            "Epoch 391/400\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.3842 - acc: 0.8062 - val_loss: 0.4953 - val_acc: 0.8000\n",
            "Epoch 392/400\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.3700 - acc: 0.8375 - val_loss: 0.5887 - val_acc: 0.7750\n",
            "Epoch 393/400\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 0.3635 - acc: 0.8375 - val_loss: 0.4918 - val_acc: 0.8000\n",
            "Epoch 394/400\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 0.3855 - acc: 0.8250 - val_loss: 0.5448 - val_acc: 0.7500\n",
            "Epoch 395/400\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 0.4158 - acc: 0.7875 - val_loss: 0.4948 - val_acc: 0.8000\n",
            "Epoch 396/400\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 0.3907 - acc: 0.8188 - val_loss: 0.5011 - val_acc: 0.7750\n",
            "Epoch 397/400\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.3738 - acc: 0.8250 - val_loss: 0.5809 - val_acc: 0.7500\n",
            "Epoch 398/400\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.3841 - acc: 0.8188 - val_loss: 0.4828 - val_acc: 0.8000\n",
            "Epoch 399/400\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.3702 - acc: 0.8375 - val_loss: 0.4788 - val_acc: 0.7500\n",
            "Epoch 400/400\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 0.3668 - acc: 0.8438 - val_loss: 0.4924 - val_acc: 0.7750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM Double Layer"
      ],
      "metadata": {
        "id": "xI3DfyDYcOV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "inputs = keras.Input(shape=(timesteps, features), batch_size=1)\n",
        "x = LSTM(16, return_sequences=True)(inputs)\n",
        "x = Dropout(0.3)(x)  # Dropout for regularization\n",
        "x = LSTM(8, return_sequences=False)(x)\n",
        "outputs = Dense(output_units, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=400, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "reNtce-ycQ0q",
        "outputId": "845352bd-e53f-4604-e86c-40ae2eae8b01"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "5/5 [==============================] - 5s 334ms/step - loss: 0.6997 - acc: 0.5063 - val_loss: 0.7005 - val_acc: 0.4750\n",
            "Epoch 2/400\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.6944 - acc: 0.5063 - val_loss: 0.6956 - val_acc: 0.4750\n",
            "Epoch 3/400\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 0.6948 - acc: 0.4875 - val_loss: 0.6939 - val_acc: 0.5250\n",
            "Epoch 4/400\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.6948 - acc: 0.4938 - val_loss: 0.6940 - val_acc: 0.5250\n",
            "Epoch 5/400\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.6943 - acc: 0.4875 - val_loss: 0.6944 - val_acc: 0.3250\n",
            "Epoch 6/400\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.6943 - acc: 0.4313 - val_loss: 0.6952 - val_acc: 0.4750\n",
            "Epoch 7/400\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.6942 - acc: 0.5063 - val_loss: 0.6951 - val_acc: 0.4500\n",
            "Epoch 8/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6939 - acc: 0.5000 - val_loss: 0.6955 - val_acc: 0.4750\n",
            "Epoch 9/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6941 - acc: 0.5063 - val_loss: 0.6953 - val_acc: 0.4750\n",
            "Epoch 10/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6953 - val_acc: 0.4750\n",
            "Epoch 11/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6954 - val_acc: 0.4750\n",
            "Epoch 12/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6938 - acc: 0.5063 - val_loss: 0.6952 - val_acc: 0.4750\n",
            "Epoch 13/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6940 - acc: 0.5063 - val_loss: 0.6954 - val_acc: 0.4750\n",
            "Epoch 14/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6955 - val_acc: 0.4750\n",
            "Epoch 15/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6954 - val_acc: 0.4750\n",
            "Epoch 16/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6954 - val_acc: 0.4750\n",
            "Epoch 17/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6952 - acc: 0.4375 - val_loss: 0.6942 - val_acc: 0.3500\n",
            "Epoch 18/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6940 - acc: 0.4375 - val_loss: 0.6944 - val_acc: 0.4500\n",
            "Epoch 19/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6939 - acc: 0.4250 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 20/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6938 - acc: 0.4500 - val_loss: 0.6944 - val_acc: 0.4500\n",
            "Epoch 21/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6940 - acc: 0.4375 - val_loss: 0.6943 - val_acc: 0.4500\n",
            "Epoch 22/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6937 - acc: 0.4625 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 23/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6948 - val_acc: 0.4750\n",
            "Epoch 24/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6954 - val_acc: 0.4750\n",
            "Epoch 25/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6952 - val_acc: 0.4750\n",
            "Epoch 26/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6940 - acc: 0.5063 - val_loss: 0.6956 - val_acc: 0.4750\n",
            "Epoch 27/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6951 - val_acc: 0.4750\n",
            "Epoch 28/400\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 0.6938 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4750\n",
            "Epoch 29/400\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 0.6941 - acc: 0.5063 - val_loss: 0.6952 - val_acc: 0.4750\n",
            "Epoch 30/400\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.6941 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 31/400\n",
            "5/5 [==============================] - 1s 189ms/step - loss: 0.6940 - acc: 0.5063 - val_loss: 0.6949 - val_acc: 0.4750\n",
            "Epoch 32/400\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.6938 - acc: 0.5063 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 33/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 34/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 35/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 36/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 37/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 38/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 39/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4750\n",
            "Epoch 40/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4750\n",
            "Epoch 41/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.6939 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 42/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6948 - val_acc: 0.4750\n",
            "Epoch 43/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6950 - val_acc: 0.4750\n",
            "Epoch 44/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6949 - val_acc: 0.4750\n",
            "Epoch 45/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6940 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 46/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6940 - acc: 0.4875 - val_loss: 0.6940 - val_acc: 0.4500\n",
            "Epoch 47/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 48/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4750\n",
            "Epoch 49/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 50/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6948 - val_acc: 0.4750\n",
            "Epoch 51/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 52/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 53/400\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.6942 - acc: 0.5063 - val_loss: 0.6949 - val_acc: 0.4750\n",
            "Epoch 54/400\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 55/400\n",
            "5/5 [==============================] - 1s 189ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 56/400\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 57/400\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 58/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 59/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 60/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6937 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 61/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.6935 - acc: 0.4938 - val_loss: 0.6938 - val_acc: 0.4500\n",
            "Epoch 62/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6946 - acc: 0.3625 - val_loss: 0.6935 - val_acc: 0.5250\n",
            "Epoch 63/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6939 - acc: 0.4625 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 64/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 65/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 66/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 67/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 68/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6948 - val_acc: 0.4750\n",
            "Epoch 69/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6950 - val_acc: 0.4750\n",
            "Epoch 70/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4750\n",
            "Epoch 71/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6947 - val_acc: 0.4750\n",
            "Epoch 72/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 73/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6940 - val_acc: 0.4750\n",
            "Epoch 74/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 75/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 76/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6944 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 77/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 78/400\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6941 - val_acc: 0.4750\n",
            "Epoch 79/400\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 80/400\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.4750\n",
            "Epoch 81/400\n",
            "5/5 [==============================] - 1s 184ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 82/400\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 83/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 84/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 85/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 86/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6946 - val_acc: 0.4750\n",
            "Epoch 87/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 88/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6943 - val_acc: 0.4750\n",
            "Epoch 89/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6940 - val_acc: 0.4750\n",
            "Epoch 90/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 91/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 92/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6940 - val_acc: 0.4750\n",
            "Epoch 93/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 94/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 95/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 96/400\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 97/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 98/400\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 99/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 100/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 101/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6945 - val_acc: 0.4750\n",
            "Epoch 102/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6939 - val_acc: 0.4750\n",
            "Epoch 103/400\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 104/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.4750\n",
            "Epoch 105/400\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 106/400\n",
            "5/5 [==============================] - 1s 186ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 107/400\n",
            "5/5 [==============================] - 1s 184ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 108/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 109/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 110/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 111/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6936 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 112/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6944 - val_acc: 0.4750\n",
            "Epoch 113/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6935 - acc: 0.5063 - val_loss: 0.6937 - val_acc: 0.4750\n",
            "Epoch 114/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4750\n",
            "Epoch 115/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 116/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 117/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 118/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 119/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 120/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 121/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 122/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6929 - val_acc: 0.4750\n",
            "Epoch 123/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6929 - val_acc: 0.4750\n",
            "Epoch 124/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 125/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4750\n",
            "Epoch 126/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6940 - val_acc: 0.4750\n",
            "Epoch 127/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6942 - val_acc: 0.4750\n",
            "Epoch 128/400\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 0.6932 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 129/400\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4750\n",
            "Epoch 130/400\n",
            "5/5 [==============================] - 1s 168ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6929 - val_acc: 0.4750\n",
            "Epoch 131/400\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 132/400\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.6928 - acc: 0.5063 - val_loss: 0.6929 - val_acc: 0.4750\n",
            "Epoch 133/400\n",
            "5/5 [==============================] - 1s 121ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 134/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6931 - val_acc: 0.4750\n",
            "Epoch 135/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6928 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4750\n",
            "Epoch 136/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 137/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 138/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6936 - val_acc: 0.4750\n",
            "Epoch 139/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 140/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6936 - acc: 0.4812 - val_loss: 0.6923 - val_acc: 0.6250\n",
            "Epoch 141/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.6937 - acc: 0.4750 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 142/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6927 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 143/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6930 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 144/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4750\n",
            "Epoch 145/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6925 - acc: 0.5063 - val_loss: 0.6930 - val_acc: 0.4750\n",
            "Epoch 146/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6933 - acc: 0.4875 - val_loss: 0.6919 - val_acc: 0.6750\n",
            "Epoch 147/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6930 - acc: 0.5312 - val_loss: 0.6916 - val_acc: 0.5500\n",
            "Epoch 148/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6930 - acc: 0.5250 - val_loss: 0.6927 - val_acc: 0.4750\n",
            "Epoch 149/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6925 - acc: 0.5063 - val_loss: 0.6926 - val_acc: 0.4750\n",
            "Epoch 150/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.6926 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 151/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6925 - acc: 0.5063 - val_loss: 0.6928 - val_acc: 0.4750\n",
            "Epoch 152/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 153/400\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.6934 - acc: 0.5063 - val_loss: 0.6938 - val_acc: 0.4750\n",
            "Epoch 154/400\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6924 - acc: 0.5063 - val_loss: 0.6933 - val_acc: 0.4750\n",
            "Epoch 155/400\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6926 - acc: 0.5063 - val_loss: 0.6922 - val_acc: 0.4750\n",
            "Epoch 156/400\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.6923 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.7000\n",
            "Epoch 157/400\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 0.6923 - acc: 0.5500 - val_loss: 0.6917 - val_acc: 0.6500\n",
            "Epoch 158/400\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 0.6926 - acc: 0.5250 - val_loss: 0.6915 - val_acc: 0.7000\n",
            "Epoch 159/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6923 - acc: 0.5312 - val_loss: 0.6921 - val_acc: 0.4750\n",
            "Epoch 160/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6922 - acc: 0.5063 - val_loss: 0.6921 - val_acc: 0.4750\n",
            "Epoch 161/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6924 - acc: 0.5063 - val_loss: 0.6925 - val_acc: 0.4750\n",
            "Epoch 162/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.6933 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.4750\n",
            "Epoch 163/400\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.6922 - acc: 0.5063 - val_loss: 0.6912 - val_acc: 0.7000\n",
            "Epoch 164/400\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.6933 - acc: 0.4688 - val_loss: 0.6902 - val_acc: 0.5500\n",
            "Epoch 165/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6936 - acc: 0.4500 - val_loss: 0.6921 - val_acc: 0.4750\n",
            "Epoch 166/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.6921 - acc: 0.5063 - val_loss: 0.6918 - val_acc: 0.4750\n",
            "Epoch 167/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6919 - acc: 0.5063 - val_loss: 0.6920 - val_acc: 0.4750\n",
            "Epoch 168/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.6929 - acc: 0.4875 - val_loss: 0.6908 - val_acc: 0.6250\n",
            "Epoch 169/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6927 - acc: 0.4750 - val_loss: 0.6923 - val_acc: 0.4750\n",
            "Epoch 170/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.6250\n",
            "Epoch 171/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.6918 - acc: 0.4812 - val_loss: 0.6912 - val_acc: 0.4750\n",
            "Epoch 172/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6929 - val_acc: 0.4750\n",
            "Epoch 173/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6951 - acc: 0.4375 - val_loss: 0.6902 - val_acc: 0.7000\n",
            "Epoch 174/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6926 - acc: 0.5188 - val_loss: 0.6914 - val_acc: 0.4750\n",
            "Epoch 175/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6920 - acc: 0.5063 - val_loss: 0.6909 - val_acc: 0.4750\n",
            "Epoch 176/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.6916 - acc: 0.5063 - val_loss: 0.6908 - val_acc: 0.4750\n",
            "Epoch 177/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6921 - acc: 0.5000 - val_loss: 0.6910 - val_acc: 0.4750\n",
            "Epoch 178/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.6919 - acc: 0.5063 - val_loss: 0.6912 - val_acc: 0.4750\n",
            "Epoch 179/400\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6918 - acc: 0.5125 - val_loss: 0.6906 - val_acc: 0.4750\n",
            "Epoch 180/400\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6915 - acc: 0.5125 - val_loss: 0.6901 - val_acc: 0.4750\n",
            "Epoch 181/400\n",
            "5/5 [==============================] - 1s 193ms/step - loss: 0.6911 - acc: 0.5375 - val_loss: 0.6885 - val_acc: 0.6750\n",
            "Epoch 182/400\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 0.6913 - acc: 0.5813 - val_loss: 0.6883 - val_acc: 0.6750\n",
            "Epoch 183/400\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 0.6914 - acc: 0.5813 - val_loss: 0.6881 - val_acc: 0.6250\n",
            "Epoch 184/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6934 - acc: 0.4875 - val_loss: 0.6905 - val_acc: 0.4750\n",
            "Epoch 185/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.6902 - acc: 0.5125 - val_loss: 0.6880 - val_acc: 0.4750\n",
            "Epoch 186/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.6899 - acc: 0.5188 - val_loss: 0.6842 - val_acc: 0.7000\n",
            "Epoch 187/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6916 - acc: 0.5437 - val_loss: 0.6809 - val_acc: 0.7000\n",
            "Epoch 188/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.6839 - acc: 0.5562 - val_loss: 0.6816 - val_acc: 0.4500\n",
            "Epoch 189/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.6687 - acc: 0.5688 - val_loss: 0.6204 - val_acc: 0.7000\n",
            "Epoch 190/400\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.6590 - acc: 0.6062 - val_loss: 0.5873 - val_acc: 0.7750\n",
            "Epoch 191/400\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.6348 - acc: 0.6562 - val_loss: 0.6046 - val_acc: 0.7500\n",
            "Epoch 192/400\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 0.6480 - acc: 0.6500 - val_loss: 0.5713 - val_acc: 0.8250\n",
            "Epoch 193/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.6351 - acc: 0.6938 - val_loss: 0.5624 - val_acc: 0.7750\n",
            "Epoch 194/400\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.6214 - acc: 0.6625 - val_loss: 0.6358 - val_acc: 0.6250\n",
            "Epoch 195/400\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.5894 - acc: 0.7000 - val_loss: 0.5698 - val_acc: 0.7000\n",
            "Epoch 196/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.6017 - acc: 0.6812 - val_loss: 0.5411 - val_acc: 0.8000\n",
            "Epoch 197/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.5780 - acc: 0.7000 - val_loss: 0.5183 - val_acc: 0.7750\n",
            "Epoch 198/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.5673 - acc: 0.7312 - val_loss: 0.5005 - val_acc: 0.8250\n",
            "Epoch 199/400\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 0.5732 - acc: 0.6812 - val_loss: 0.5035 - val_acc: 0.8000\n",
            "Epoch 200/400\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 0.5478 - acc: 0.7188 - val_loss: 0.5180 - val_acc: 0.7250\n",
            "Epoch 201/400\n",
            "5/5 [==============================] - 1s 189ms/step - loss: 0.5512 - acc: 0.7063 - val_loss: 0.4771 - val_acc: 0.8000\n",
            "Epoch 202/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.5224 - acc: 0.7375 - val_loss: 0.5188 - val_acc: 0.7500\n",
            "Epoch 203/400\n",
            "5/5 [==============================] - 1s 189ms/step - loss: 0.5393 - acc: 0.7250 - val_loss: 0.5021 - val_acc: 0.7750\n",
            "Epoch 204/400\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.5635 - acc: 0.6812 - val_loss: 0.5311 - val_acc: 0.7750\n",
            "Epoch 205/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.6494 - acc: 0.6313 - val_loss: 0.5625 - val_acc: 0.6750\n",
            "Epoch 206/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.5766 - acc: 0.6938 - val_loss: 0.5903 - val_acc: 0.7000\n",
            "Epoch 207/400\n",
            "5/5 [==============================] - 0s 106ms/step - loss: 0.6289 - acc: 0.6500 - val_loss: 0.5876 - val_acc: 0.7000\n",
            "Epoch 208/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6561 - acc: 0.5437 - val_loss: 0.6427 - val_acc: 0.6500\n",
            "Epoch 209/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.6399 - acc: 0.6625 - val_loss: 0.5987 - val_acc: 0.7000\n",
            "Epoch 210/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.6122 - acc: 0.7188 - val_loss: 0.5505 - val_acc: 0.8000\n",
            "Epoch 211/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.5606 - acc: 0.7063 - val_loss: 0.4837 - val_acc: 0.8000\n",
            "Epoch 212/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.5194 - acc: 0.7437 - val_loss: 0.5226 - val_acc: 0.7500\n",
            "Epoch 213/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.5140 - acc: 0.7500 - val_loss: 0.5190 - val_acc: 0.7750\n",
            "Epoch 214/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.5208 - acc: 0.7312 - val_loss: 0.5235 - val_acc: 0.7750\n",
            "Epoch 215/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.5186 - acc: 0.7437 - val_loss: 0.4985 - val_acc: 0.7750\n",
            "Epoch 216/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4957 - acc: 0.7500 - val_loss: 0.5108 - val_acc: 0.8000\n",
            "Epoch 217/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.5008 - acc: 0.7312 - val_loss: 0.4913 - val_acc: 0.8000\n",
            "Epoch 218/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.4911 - acc: 0.7500 - val_loss: 0.4917 - val_acc: 0.8000\n",
            "Epoch 219/400\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.4972 - acc: 0.7437 - val_loss: 0.5086 - val_acc: 0.7750\n",
            "Epoch 220/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4947 - acc: 0.7500 - val_loss: 0.4898 - val_acc: 0.7750\n",
            "Epoch 221/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4940 - acc: 0.7500 - val_loss: 0.4739 - val_acc: 0.8000\n",
            "Epoch 222/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4886 - acc: 0.7688 - val_loss: 0.5456 - val_acc: 0.7250\n",
            "Epoch 223/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4915 - acc: 0.7437 - val_loss: 0.4832 - val_acc: 0.7750\n",
            "Epoch 224/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.5545 - acc: 0.7063 - val_loss: 0.9730 - val_acc: 0.3750\n",
            "Epoch 225/400\n",
            "5/5 [==============================] - 1s 185ms/step - loss: 0.5935 - acc: 0.6562 - val_loss: 0.5026 - val_acc: 0.7500\n",
            "Epoch 226/400\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.5694 - acc: 0.6625 - val_loss: 0.5014 - val_acc: 0.7500\n",
            "Epoch 227/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.5499 - acc: 0.7125 - val_loss: 0.4879 - val_acc: 0.7500\n",
            "Epoch 228/400\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 0.5229 - acc: 0.7375 - val_loss: 0.5541 - val_acc: 0.7000\n",
            "Epoch 229/400\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.5110 - acc: 0.7375 - val_loss: 0.4969 - val_acc: 0.7750\n",
            "Epoch 230/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.5068 - acc: 0.7437 - val_loss: 0.4800 - val_acc: 0.7500\n",
            "Epoch 231/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4970 - acc: 0.7563 - val_loss: 0.4843 - val_acc: 0.8000\n",
            "Epoch 232/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4878 - acc: 0.7688 - val_loss: 0.5174 - val_acc: 0.7250\n",
            "Epoch 233/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4932 - acc: 0.7563 - val_loss: 0.4934 - val_acc: 0.8000\n",
            "Epoch 234/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4839 - acc: 0.7563 - val_loss: 0.4997 - val_acc: 0.7750\n",
            "Epoch 235/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.4801 - acc: 0.7563 - val_loss: 0.5059 - val_acc: 0.7750\n",
            "Epoch 236/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4851 - acc: 0.7437 - val_loss: 0.5043 - val_acc: 0.7750\n",
            "Epoch 237/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4819 - acc: 0.7500 - val_loss: 0.4827 - val_acc: 0.8000\n",
            "Epoch 238/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4920 - acc: 0.7563 - val_loss: 0.5343 - val_acc: 0.7500\n",
            "Epoch 239/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.4907 - acc: 0.7375 - val_loss: 0.4773 - val_acc: 0.8000\n",
            "Epoch 240/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4853 - acc: 0.7625 - val_loss: 0.4804 - val_acc: 0.8000\n",
            "Epoch 241/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4773 - acc: 0.7688 - val_loss: 0.5114 - val_acc: 0.7500\n",
            "Epoch 242/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4785 - acc: 0.7625 - val_loss: 0.4814 - val_acc: 0.8000\n",
            "Epoch 243/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4764 - acc: 0.7563 - val_loss: 0.4792 - val_acc: 0.8000\n",
            "Epoch 244/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4690 - acc: 0.7625 - val_loss: 0.5296 - val_acc: 0.7500\n",
            "Epoch 245/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.4978 - acc: 0.7437 - val_loss: 0.4843 - val_acc: 0.7750\n",
            "Epoch 246/400\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.5298 - acc: 0.7063 - val_loss: 0.4692 - val_acc: 0.7750\n",
            "Epoch 247/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.5217 - acc: 0.7312 - val_loss: 0.4990 - val_acc: 0.8000\n",
            "Epoch 248/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.5202 - acc: 0.7188 - val_loss: 0.5019 - val_acc: 0.7750\n",
            "Epoch 249/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.5292 - acc: 0.7125 - val_loss: 0.4862 - val_acc: 0.7500\n",
            "Epoch 250/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.5095 - acc: 0.7375 - val_loss: 0.4876 - val_acc: 0.8000\n",
            "Epoch 251/400\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 0.5080 - acc: 0.7125 - val_loss: 0.4981 - val_acc: 0.8000\n",
            "Epoch 252/400\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 0.5008 - acc: 0.7375 - val_loss: 0.5081 - val_acc: 0.7750\n",
            "Epoch 253/400\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.5087 - acc: 0.7375 - val_loss: 0.5218 - val_acc: 0.7750\n",
            "Epoch 254/400\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.4918 - acc: 0.7500 - val_loss: 0.5216 - val_acc: 0.8000\n",
            "Epoch 255/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4896 - acc: 0.7437 - val_loss: 0.4932 - val_acc: 0.8000\n",
            "Epoch 256/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4864 - acc: 0.7563 - val_loss: 0.4904 - val_acc: 0.8000\n",
            "Epoch 257/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4788 - acc: 0.7688 - val_loss: 0.5083 - val_acc: 0.7750\n",
            "Epoch 258/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4801 - acc: 0.7625 - val_loss: 0.5152 - val_acc: 0.7750\n",
            "Epoch 259/400\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.4813 - acc: 0.7437 - val_loss: 0.4960 - val_acc: 0.8000\n",
            "Epoch 260/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4766 - acc: 0.7563 - val_loss: 0.4784 - val_acc: 0.8000\n",
            "Epoch 261/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.4769 - acc: 0.7625 - val_loss: 0.4940 - val_acc: 0.8000\n",
            "Epoch 262/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4790 - acc: 0.7437 - val_loss: 0.5068 - val_acc: 0.8000\n",
            "Epoch 263/400\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4764 - acc: 0.7625 - val_loss: 0.4898 - val_acc: 0.8000\n",
            "Epoch 264/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.4709 - acc: 0.7625 - val_loss: 0.5312 - val_acc: 0.7750\n",
            "Epoch 265/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4757 - acc: 0.7563 - val_loss: 0.4952 - val_acc: 0.7750\n",
            "Epoch 266/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.4739 - acc: 0.7563 - val_loss: 0.5079 - val_acc: 0.7750\n",
            "Epoch 267/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4692 - acc: 0.7625 - val_loss: 0.5120 - val_acc: 0.8000\n",
            "Epoch 268/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4693 - acc: 0.7563 - val_loss: 0.5142 - val_acc: 0.8000\n",
            "Epoch 269/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4713 - acc: 0.7500 - val_loss: 0.4982 - val_acc: 0.8000\n",
            "Epoch 270/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4668 - acc: 0.7688 - val_loss: 0.4939 - val_acc: 0.8000\n",
            "Epoch 271/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4777 - acc: 0.7625 - val_loss: 0.4595 - val_acc: 0.8000\n",
            "Epoch 272/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4794 - acc: 0.7563 - val_loss: 0.4848 - val_acc: 0.8000\n",
            "Epoch 273/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4781 - acc: 0.7437 - val_loss: 0.4800 - val_acc: 0.8000\n",
            "Epoch 274/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4794 - acc: 0.7563 - val_loss: 0.4747 - val_acc: 0.8000\n",
            "Epoch 275/400\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.4780 - acc: 0.7563 - val_loss: 0.5393 - val_acc: 0.7500\n",
            "Epoch 276/400\n",
            "5/5 [==============================] - 1s 205ms/step - loss: 0.4842 - acc: 0.7375 - val_loss: 0.4580 - val_acc: 0.8000\n",
            "Epoch 277/400\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.4799 - acc: 0.7250 - val_loss: 0.5843 - val_acc: 0.7250\n",
            "Epoch 278/400\n",
            "5/5 [==============================] - 1s 195ms/step - loss: 0.4742 - acc: 0.7625 - val_loss: 0.4724 - val_acc: 0.8000\n",
            "Epoch 279/400\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 0.4712 - acc: 0.7625 - val_loss: 0.4867 - val_acc: 0.8000\n",
            "Epoch 280/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.4632 - acc: 0.7625 - val_loss: 0.5182 - val_acc: 0.7750\n",
            "Epoch 281/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4530 - acc: 0.7750 - val_loss: 0.4891 - val_acc: 0.8000\n",
            "Epoch 282/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4579 - acc: 0.7625 - val_loss: 0.5037 - val_acc: 0.7750\n",
            "Epoch 283/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4564 - acc: 0.7812 - val_loss: 0.4951 - val_acc: 0.8000\n",
            "Epoch 284/400\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.4495 - acc: 0.7937 - val_loss: 0.5621 - val_acc: 0.7000\n",
            "Epoch 285/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4601 - acc: 0.7625 - val_loss: 0.5135 - val_acc: 0.7750\n",
            "Epoch 286/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4690 - acc: 0.7750 - val_loss: 0.5297 - val_acc: 0.7500\n",
            "Epoch 287/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4684 - acc: 0.7750 - val_loss: 0.4869 - val_acc: 0.8000\n",
            "Epoch 288/400\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.4728 - acc: 0.7750 - val_loss: 0.4788 - val_acc: 0.8000\n",
            "Epoch 289/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4797 - acc: 0.7625 - val_loss: 0.4659 - val_acc: 0.8000\n",
            "Epoch 290/400\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.4731 - acc: 0.7500 - val_loss: 0.4645 - val_acc: 0.8000\n",
            "Epoch 291/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4988 - acc: 0.7250 - val_loss: 0.4458 - val_acc: 0.8000\n",
            "Epoch 292/400\n",
            "5/5 [==============================] - 1s 102ms/step - loss: 0.4896 - acc: 0.7312 - val_loss: 0.4475 - val_acc: 0.8000\n",
            "Epoch 293/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.5419 - acc: 0.7000 - val_loss: 0.5508 - val_acc: 0.7500\n",
            "Epoch 294/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.6011 - acc: 0.6625 - val_loss: 0.5577 - val_acc: 0.7000\n",
            "Epoch 295/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.5895 - acc: 0.6750 - val_loss: 0.5139 - val_acc: 0.7500\n",
            "Epoch 296/400\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.5367 - acc: 0.7063 - val_loss: 0.4525 - val_acc: 0.7750\n",
            "Epoch 297/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4930 - acc: 0.7375 - val_loss: 0.5474 - val_acc: 0.7500\n",
            "Epoch 298/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4669 - acc: 0.7750 - val_loss: 0.5128 - val_acc: 0.8000\n",
            "Epoch 299/400\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.5162 - acc: 0.6938 - val_loss: 0.5228 - val_acc: 0.7500\n",
            "Epoch 300/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.4706 - acc: 0.7625 - val_loss: 0.4392 - val_acc: 0.7750\n",
            "Epoch 301/400\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 0.4885 - acc: 0.7500 - val_loss: 0.4435 - val_acc: 0.7750\n",
            "Epoch 302/400\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.4731 - acc: 0.7625 - val_loss: 0.5014 - val_acc: 0.7750\n",
            "Epoch 303/400\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.4729 - acc: 0.7563 - val_loss: 0.5191 - val_acc: 0.7750\n",
            "Epoch 304/400\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.4723 - acc: 0.7625 - val_loss: 0.4511 - val_acc: 0.8000\n",
            "Epoch 305/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4755 - acc: 0.7500 - val_loss: 0.4683 - val_acc: 0.8000\n",
            "Epoch 306/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4721 - acc: 0.7688 - val_loss: 0.5326 - val_acc: 0.7500\n",
            "Epoch 307/400\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.4656 - acc: 0.7563 - val_loss: 0.4562 - val_acc: 0.8000\n",
            "Epoch 308/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4615 - acc: 0.7625 - val_loss: 0.4991 - val_acc: 0.8000\n",
            "Epoch 309/400\n",
            "5/5 [==============================] - 1s 103ms/step - loss: 0.4859 - acc: 0.7375 - val_loss: 0.4709 - val_acc: 0.8000\n",
            "Epoch 310/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4950 - acc: 0.7500 - val_loss: 0.4846 - val_acc: 0.7750\n",
            "Epoch 311/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4748 - acc: 0.7688 - val_loss: 0.5781 - val_acc: 0.7250\n",
            "Epoch 312/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4847 - acc: 0.7500 - val_loss: 0.4689 - val_acc: 0.7500\n",
            "Epoch 313/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4911 - acc: 0.7500 - val_loss: 0.4822 - val_acc: 0.7750\n",
            "Epoch 314/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4824 - acc: 0.7563 - val_loss: 0.5303 - val_acc: 0.7500\n",
            "Epoch 315/400\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.4800 - acc: 0.7437 - val_loss: 0.4769 - val_acc: 0.8000\n",
            "Epoch 316/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4714 - acc: 0.7625 - val_loss: 0.4599 - val_acc: 0.8000\n",
            "Epoch 317/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4657 - acc: 0.7688 - val_loss: 0.4769 - val_acc: 0.8000\n",
            "Epoch 318/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4583 - acc: 0.7750 - val_loss: 0.5076 - val_acc: 0.7750\n",
            "Epoch 319/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4494 - acc: 0.7875 - val_loss: 0.4738 - val_acc: 0.8000\n",
            "Epoch 320/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4573 - acc: 0.7750 - val_loss: 0.5261 - val_acc: 0.7750\n",
            "Epoch 321/400\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.4624 - acc: 0.7688 - val_loss: 0.4892 - val_acc: 0.8000\n",
            "Epoch 322/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4817 - acc: 0.7437 - val_loss: 0.5019 - val_acc: 0.7750\n",
            "Epoch 323/400\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.4690 - acc: 0.7375 - val_loss: 0.6591 - val_acc: 0.6750\n",
            "Epoch 324/400\n",
            "5/5 [==============================] - 1s 187ms/step - loss: 0.4854 - acc: 0.7437 - val_loss: 0.4758 - val_acc: 0.7500\n",
            "Epoch 325/400\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.5009 - acc: 0.7437 - val_loss: 0.4394 - val_acc: 0.7750\n",
            "Epoch 326/400\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.4907 - acc: 0.7563 - val_loss: 0.4623 - val_acc: 0.8000\n",
            "Epoch 327/400\n",
            "5/5 [==============================] - 1s 198ms/step - loss: 0.4699 - acc: 0.7625 - val_loss: 0.5229 - val_acc: 0.8000\n",
            "Epoch 328/400\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.4738 - acc: 0.7500 - val_loss: 0.4791 - val_acc: 0.8000\n",
            "Epoch 329/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4690 - acc: 0.7500 - val_loss: 0.4561 - val_acc: 0.8000\n",
            "Epoch 330/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.4652 - acc: 0.7688 - val_loss: 0.5186 - val_acc: 0.7500\n",
            "Epoch 331/400\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.4660 - acc: 0.7563 - val_loss: 0.4855 - val_acc: 0.8000\n",
            "Epoch 332/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4577 - acc: 0.7688 - val_loss: 0.4925 - val_acc: 0.8000\n",
            "Epoch 333/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4485 - acc: 0.7750 - val_loss: 0.5211 - val_acc: 0.8000\n",
            "Epoch 334/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4483 - acc: 0.7750 - val_loss: 0.4952 - val_acc: 0.8000\n",
            "Epoch 335/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4432 - acc: 0.7875 - val_loss: 0.4854 - val_acc: 0.8000\n",
            "Epoch 336/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.4577 - acc: 0.7875 - val_loss: 0.5481 - val_acc: 0.7750\n",
            "Epoch 337/400\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 0.4535 - acc: 0.7688 - val_loss: 0.5184 - val_acc: 0.7750\n",
            "Epoch 338/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4638 - acc: 0.7688 - val_loss: 0.5226 - val_acc: 0.7750\n",
            "Epoch 339/400\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.4642 - acc: 0.7625 - val_loss: 0.5107 - val_acc: 0.8000\n",
            "Epoch 340/400\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.4712 - acc: 0.7625 - val_loss: 0.4634 - val_acc: 0.8000\n",
            "Epoch 341/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4615 - acc: 0.7563 - val_loss: 0.5141 - val_acc: 0.8000\n",
            "Epoch 342/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4611 - acc: 0.7625 - val_loss: 0.4677 - val_acc: 0.8000\n",
            "Epoch 343/400\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 0.4651 - acc: 0.7688 - val_loss: 0.4747 - val_acc: 0.8000\n",
            "Epoch 344/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4515 - acc: 0.7750 - val_loss: 0.5629 - val_acc: 0.7500\n",
            "Epoch 345/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4655 - acc: 0.7563 - val_loss: 0.4776 - val_acc: 0.8000\n",
            "Epoch 346/400\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.4673 - acc: 0.7375 - val_loss: 0.5757 - val_acc: 0.7500\n",
            "Epoch 347/400\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.4685 - acc: 0.7875 - val_loss: 0.5205 - val_acc: 0.7750\n",
            "Epoch 348/400\n",
            "5/5 [==============================] - 1s 188ms/step - loss: 0.4561 - acc: 0.7750 - val_loss: 0.5040 - val_acc: 0.7750\n",
            "Epoch 349/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.4610 - acc: 0.7563 - val_loss: 0.5294 - val_acc: 0.7750\n",
            "Epoch 350/400\n",
            "5/5 [==============================] - 1s 180ms/step - loss: 0.4493 - acc: 0.7688 - val_loss: 0.5019 - val_acc: 0.8000\n",
            "Epoch 351/400\n",
            "5/5 [==============================] - 1s 170ms/step - loss: 0.4487 - acc: 0.7688 - val_loss: 0.5183 - val_acc: 0.8000\n",
            "Epoch 352/400\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.5255 - acc: 0.7063 - val_loss: 0.4266 - val_acc: 0.8000\n",
            "Epoch 353/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4998 - acc: 0.7000 - val_loss: 0.5385 - val_acc: 0.7750\n",
            "Epoch 354/400\n",
            "5/5 [==============================] - 1s 111ms/step - loss: 0.4922 - acc: 0.7437 - val_loss: 0.4441 - val_acc: 0.7750\n",
            "Epoch 355/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.5127 - acc: 0.7375 - val_loss: 0.4365 - val_acc: 0.7750\n",
            "Epoch 356/400\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.4894 - acc: 0.7500 - val_loss: 0.5037 - val_acc: 0.8000\n",
            "Epoch 357/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4595 - acc: 0.7625 - val_loss: 0.5314 - val_acc: 0.7500\n",
            "Epoch 358/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4496 - acc: 0.7812 - val_loss: 0.5170 - val_acc: 0.7750\n",
            "Epoch 359/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4490 - acc: 0.7750 - val_loss: 0.5168 - val_acc: 0.7750\n",
            "Epoch 360/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4436 - acc: 0.7688 - val_loss: 0.5093 - val_acc: 0.7750\n",
            "Epoch 361/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4403 - acc: 0.7750 - val_loss: 0.4974 - val_acc: 0.7750\n",
            "Epoch 362/400\n",
            "5/5 [==============================] - 1s 105ms/step - loss: 0.4352 - acc: 0.7750 - val_loss: 0.4806 - val_acc: 0.8000\n",
            "Epoch 363/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4393 - acc: 0.7688 - val_loss: 0.5057 - val_acc: 0.7750\n",
            "Epoch 364/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4408 - acc: 0.7750 - val_loss: 0.4796 - val_acc: 0.8000\n",
            "Epoch 365/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4335 - acc: 0.7937 - val_loss: 0.4911 - val_acc: 0.8000\n",
            "Epoch 366/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4473 - acc: 0.7688 - val_loss: 0.4905 - val_acc: 0.7750\n",
            "Epoch 367/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4360 - acc: 0.7875 - val_loss: 0.5251 - val_acc: 0.7750\n",
            "Epoch 368/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4521 - acc: 0.7625 - val_loss: 0.5123 - val_acc: 0.7750\n",
            "Epoch 369/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.4435 - acc: 0.7875 - val_loss: 0.4968 - val_acc: 0.7750\n",
            "Epoch 370/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4338 - acc: 0.7875 - val_loss: 0.5781 - val_acc: 0.7750\n",
            "Epoch 371/400\n",
            "5/5 [==============================] - 0s 104ms/step - loss: 0.4469 - acc: 0.7750 - val_loss: 0.4743 - val_acc: 0.8000\n",
            "Epoch 372/400\n",
            "5/5 [==============================] - 1s 176ms/step - loss: 0.4840 - acc: 0.7437 - val_loss: 0.4685 - val_acc: 0.7750\n",
            "Epoch 373/400\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 0.4775 - acc: 0.7500 - val_loss: 0.5013 - val_acc: 0.8500\n",
            "Epoch 374/400\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 0.5062 - acc: 0.7437 - val_loss: 0.4460 - val_acc: 0.7750\n",
            "Epoch 375/400\n",
            "5/5 [==============================] - 1s 177ms/step - loss: 0.5135 - acc: 0.7437 - val_loss: 0.4344 - val_acc: 0.7750\n",
            "Epoch 376/400\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 0.5048 - acc: 0.7500 - val_loss: 0.4949 - val_acc: 0.7750\n",
            "Epoch 377/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4643 - acc: 0.7563 - val_loss: 0.6076 - val_acc: 0.6750\n",
            "Epoch 378/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4764 - acc: 0.7688 - val_loss: 0.4617 - val_acc: 0.7750\n",
            "Epoch 379/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4987 - acc: 0.7312 - val_loss: 0.4485 - val_acc: 0.8000\n",
            "Epoch 380/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4821 - acc: 0.7563 - val_loss: 0.5083 - val_acc: 0.8250\n",
            "Epoch 381/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4889 - acc: 0.7563 - val_loss: 0.4330 - val_acc: 0.7750\n",
            "Epoch 382/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4906 - acc: 0.7625 - val_loss: 0.4988 - val_acc: 0.7750\n",
            "Epoch 383/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4837 - acc: 0.7563 - val_loss: 0.5760 - val_acc: 0.8000\n",
            "Epoch 384/400\n",
            "5/5 [==============================] - 0s 103ms/step - loss: 0.4821 - acc: 0.7437 - val_loss: 0.5268 - val_acc: 0.7750\n",
            "Epoch 385/400\n",
            "5/5 [==============================] - 1s 108ms/step - loss: 0.4907 - acc: 0.7250 - val_loss: 0.4748 - val_acc: 0.7750\n",
            "Epoch 386/400\n",
            "5/5 [==============================] - 0s 102ms/step - loss: 0.4754 - acc: 0.7688 - val_loss: 0.5946 - val_acc: 0.7500\n",
            "Epoch 387/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4782 - acc: 0.7625 - val_loss: 0.4663 - val_acc: 0.7750\n",
            "Epoch 388/400\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.4798 - acc: 0.7500 - val_loss: 0.4412 - val_acc: 0.7750\n",
            "Epoch 389/400\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.4697 - acc: 0.7500 - val_loss: 0.5441 - val_acc: 0.7750\n",
            "Epoch 390/400\n",
            "5/5 [==============================] - 1s 104ms/step - loss: 0.4670 - acc: 0.7688 - val_loss: 0.5046 - val_acc: 0.7750\n",
            "Epoch 391/400\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.4673 - acc: 0.7750 - val_loss: 0.4275 - val_acc: 0.7750\n",
            "Epoch 392/400\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.4708 - acc: 0.7563 - val_loss: 0.4909 - val_acc: 0.7750\n",
            "Epoch 393/400\n",
            "5/5 [==============================] - 1s 121ms/step - loss: 0.4795 - acc: 0.7688 - val_loss: 0.5561 - val_acc: 0.7750\n",
            "Epoch 394/400\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 0.4571 - acc: 0.7750 - val_loss: 0.4790 - val_acc: 0.7750\n",
            "Epoch 395/400\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 0.4618 - acc: 0.7688 - val_loss: 0.4837 - val_acc: 0.7750\n",
            "Epoch 396/400\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.4572 - acc: 0.7625 - val_loss: 0.5170 - val_acc: 0.8000\n",
            "Epoch 397/400\n",
            "5/5 [==============================] - 1s 181ms/step - loss: 0.4527 - acc: 0.7563 - val_loss: 0.5159 - val_acc: 0.8000\n",
            "Epoch 398/400\n",
            "5/5 [==============================] - 1s 182ms/step - loss: 0.4483 - acc: 0.7625 - val_loss: 0.4984 - val_acc: 0.7750\n",
            "Epoch 399/400\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 0.4527 - acc: 0.7688 - val_loss: 0.5142 - val_acc: 0.8000\n",
            "Epoch 400/400\n",
            "5/5 [==============================] - 1s 194ms/step - loss: 0.4458 - acc: 0.7625 - val_loss: 0.4963 - val_acc: 0.7750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conv1D Single Layer"
      ],
      "metadata": {
        "id": "2Lq9Lc2izEuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "timesteps = 176\n",
        "features = 6\n",
        "output_units = 2\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Input(shape=(timesteps, features), batch_size=1),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "\n",
        "    MaxPooling1D(pool_size=2),  # Adding MaxPooling1D for reducing dimensionality\n",
        "    Flatten(),  # Flatten the output to fit into Dense layer\n",
        "    Dense(output_units, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "w8qUdim5kG_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7179739e-9dac-4c24-cae1-67792cd06c9c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 73ms/step - loss: 0.7206 - accuracy: 0.4938 - val_loss: 0.6941 - val_accuracy: 0.5250\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6909 - accuracy: 0.5188 - val_loss: 0.6958 - val_accuracy: 0.4750\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6722 - accuracy: 0.5500 - val_loss: 0.6654 - val_accuracy: 0.6500\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6549 - accuracy: 0.7063 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6364 - accuracy: 0.7688 - val_loss: 0.6457 - val_accuracy: 0.6250\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.6209 - accuracy: 0.6938 - val_loss: 0.6304 - val_accuracy: 0.7500\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.6139 - accuracy: 0.7063 - val_loss: 0.6177 - val_accuracy: 0.7000\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5990 - accuracy: 0.6812 - val_loss: 0.6193 - val_accuracy: 0.5500\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5893 - accuracy: 0.7312 - val_loss: 0.6004 - val_accuracy: 0.7250\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.6034 - val_accuracy: 0.5750\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5501 - accuracy: 0.7125 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5378 - accuracy: 0.7563 - val_loss: 0.5762 - val_accuracy: 0.8000\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5311 - accuracy: 0.7500 - val_loss: 0.5651 - val_accuracy: 0.7500\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5151 - accuracy: 0.7937 - val_loss: 0.5628 - val_accuracy: 0.8000\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5085 - accuracy: 0.7437 - val_loss: 0.5558 - val_accuracy: 0.8000\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4917 - accuracy: 0.8188 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5033 - accuracy: 0.7437 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.5179 - accuracy: 0.6812 - val_loss: 0.5430 - val_accuracy: 0.8250\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4895 - accuracy: 0.7625 - val_loss: 0.5397 - val_accuracy: 0.7750\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4689 - accuracy: 0.8188 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4723 - accuracy: 0.7750 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4566 - accuracy: 0.8313 - val_loss: 0.5279 - val_accuracy: 0.8000\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4534 - accuracy: 0.8062 - val_loss: 0.5224 - val_accuracy: 0.8000\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4477 - accuracy: 0.8250 - val_loss: 0.5211 - val_accuracy: 0.8000\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4483 - accuracy: 0.8000 - val_loss: 0.5154 - val_accuracy: 0.7750\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4502 - accuracy: 0.7688 - val_loss: 0.5307 - val_accuracy: 0.6500\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4542 - accuracy: 0.7563 - val_loss: 0.5170 - val_accuracy: 0.7750\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4267 - accuracy: 0.8188 - val_loss: 0.5184 - val_accuracy: 0.7750\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4395 - accuracy: 0.7688 - val_loss: 0.5097 - val_accuracy: 0.7750\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4381 - accuracy: 0.8250 - val_loss: 0.5176 - val_accuracy: 0.7750\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4301 - accuracy: 0.8250 - val_loss: 0.5184 - val_accuracy: 0.7250\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4176 - accuracy: 0.8313 - val_loss: 0.4998 - val_accuracy: 0.7750\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4100 - accuracy: 0.8188 - val_loss: 0.4969 - val_accuracy: 0.7750\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4065 - accuracy: 0.8438 - val_loss: 0.4967 - val_accuracy: 0.7750\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4036 - accuracy: 0.8313 - val_loss: 0.4945 - val_accuracy: 0.7750\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3964 - accuracy: 0.8313 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3990 - accuracy: 0.8250 - val_loss: 0.4937 - val_accuracy: 0.7750\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3972 - accuracy: 0.8375 - val_loss: 0.4990 - val_accuracy: 0.7750\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3886 - accuracy: 0.8375 - val_loss: 0.4965 - val_accuracy: 0.7250\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3895 - accuracy: 0.8313 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3894 - accuracy: 0.8500 - val_loss: 0.4880 - val_accuracy: 0.7750\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3877 - accuracy: 0.8313 - val_loss: 0.4909 - val_accuracy: 0.7500\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3768 - accuracy: 0.8500 - val_loss: 0.4918 - val_accuracy: 0.7750\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3785 - accuracy: 0.8375 - val_loss: 0.4841 - val_accuracy: 0.7750\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3703 - accuracy: 0.8625 - val_loss: 0.4831 - val_accuracy: 0.7750\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3704 - accuracy: 0.8562 - val_loss: 0.4795 - val_accuracy: 0.8000\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3722 - accuracy: 0.8438 - val_loss: 0.4806 - val_accuracy: 0.8000\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3589 - accuracy: 0.8750 - val_loss: 0.4808 - val_accuracy: 0.8000\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3576 - accuracy: 0.8687 - val_loss: 0.4783 - val_accuracy: 0.8000\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3560 - accuracy: 0.8687 - val_loss: 0.4772 - val_accuracy: 0.8000\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3504 - accuracy: 0.8687 - val_loss: 0.4792 - val_accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3522 - accuracy: 0.8625 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3817 - accuracy: 0.8000 - val_loss: 0.4815 - val_accuracy: 0.8000\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3600 - accuracy: 0.8438 - val_loss: 0.5056 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3555 - accuracy: 0.8562 - val_loss: 0.4814 - val_accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3484 - accuracy: 0.8438 - val_loss: 0.4766 - val_accuracy: 0.8250\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3422 - accuracy: 0.8625 - val_loss: 0.4788 - val_accuracy: 0.8000\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3402 - accuracy: 0.8750 - val_loss: 0.4791 - val_accuracy: 0.7750\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3413 - accuracy: 0.8750 - val_loss: 0.4844 - val_accuracy: 0.8000\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3313 - accuracy: 0.8562 - val_loss: 0.4803 - val_accuracy: 0.8250\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3329 - accuracy: 0.8687 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3335 - accuracy: 0.8687 - val_loss: 0.4809 - val_accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3423 - accuracy: 0.8438 - val_loss: 0.4823 - val_accuracy: 0.7750\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3314 - accuracy: 0.8750 - val_loss: 0.4926 - val_accuracy: 0.8000\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3250 - accuracy: 0.8562 - val_loss: 0.4704 - val_accuracy: 0.8250\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3328 - accuracy: 0.8687 - val_loss: 0.4711 - val_accuracy: 0.8250\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3284 - accuracy: 0.8500 - val_loss: 0.4913 - val_accuracy: 0.7750\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3213 - accuracy: 0.8750 - val_loss: 0.4787 - val_accuracy: 0.8250\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3220 - accuracy: 0.8625 - val_loss: 0.4772 - val_accuracy: 0.8250\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3220 - accuracy: 0.8625 - val_loss: 0.4944 - val_accuracy: 0.7750\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3276 - accuracy: 0.8687 - val_loss: 0.4837 - val_accuracy: 0.7750\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3130 - accuracy: 0.8875 - val_loss: 0.4836 - val_accuracy: 0.8000\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.3149 - accuracy: 0.8500 - val_loss: 0.4791 - val_accuracy: 0.8250\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3114 - accuracy: 0.8687 - val_loss: 0.4782 - val_accuracy: 0.8250\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3030 - accuracy: 0.8875 - val_loss: 0.4846 - val_accuracy: 0.8250\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.3048 - accuracy: 0.8938 - val_loss: 0.4835 - val_accuracy: 0.8250\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.2994 - accuracy: 0.8750 - val_loss: 0.4823 - val_accuracy: 0.8250\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2968 - accuracy: 0.8875 - val_loss: 0.4795 - val_accuracy: 0.8250\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2974 - accuracy: 0.8875 - val_loss: 0.4821 - val_accuracy: 0.8250\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2983 - accuracy: 0.8750 - val_loss: 0.4800 - val_accuracy: 0.8250\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2955 - accuracy: 0.8938 - val_loss: 0.4837 - val_accuracy: 0.8250\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2894 - accuracy: 0.8938 - val_loss: 0.4791 - val_accuracy: 0.8500\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2901 - accuracy: 0.8938 - val_loss: 0.4793 - val_accuracy: 0.8500\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2884 - accuracy: 0.9000 - val_loss: 0.4797 - val_accuracy: 0.8500\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2863 - accuracy: 0.9000 - val_loss: 0.4829 - val_accuracy: 0.8250\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2834 - accuracy: 0.9000 - val_loss: 0.4853 - val_accuracy: 0.8250\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2825 - accuracy: 0.8938 - val_loss: 0.4820 - val_accuracy: 0.8250\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2869 - accuracy: 0.9062 - val_loss: 0.4844 - val_accuracy: 0.8250\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2877 - accuracy: 0.8750 - val_loss: 0.4839 - val_accuracy: 0.8500\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2786 - accuracy: 0.9000 - val_loss: 0.4828 - val_accuracy: 0.8500\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2777 - accuracy: 0.9125 - val_loss: 0.4860 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2800 - accuracy: 0.8875 - val_loss: 0.4837 - val_accuracy: 0.8500\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.2782 - accuracy: 0.9062 - val_loss: 0.4839 - val_accuracy: 0.8500\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.2830 - accuracy: 0.8813 - val_loss: 0.5039 - val_accuracy: 0.8250\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2708 - accuracy: 0.8938 - val_loss: 0.4843 - val_accuracy: 0.8250\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2740 - accuracy: 0.9000 - val_loss: 0.4871 - val_accuracy: 0.8500\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2727 - accuracy: 0.8813 - val_loss: 0.4919 - val_accuracy: 0.8250\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2657 - accuracy: 0.9062 - val_loss: 0.4868 - val_accuracy: 0.8500\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2676 - accuracy: 0.9187 - val_loss: 0.4952 - val_accuracy: 0.8250\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.2645 - accuracy: 0.9125 - val_loss: 0.4855 - val_accuracy: 0.8500\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2664 - accuracy: 0.9125 - val_loss: 0.4931 - val_accuracy: 0.8250\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.2765 - accuracy: 0.8813 - val_loss: 0.4955 - val_accuracy: 0.8500\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.2687 - accuracy: 0.9062 - val_loss: 0.4936 - val_accuracy: 0.8250\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2685 - accuracy: 0.9000 - val_loss: 0.5053 - val_accuracy: 0.8250\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2646 - accuracy: 0.9000 - val_loss: 0.4938 - val_accuracy: 0.8500\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2569 - accuracy: 0.9062 - val_loss: 0.5011 - val_accuracy: 0.8250\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2583 - accuracy: 0.8938 - val_loss: 0.4936 - val_accuracy: 0.8500\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2515 - accuracy: 0.9187 - val_loss: 0.4906 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2554 - accuracy: 0.9125 - val_loss: 0.4945 - val_accuracy: 0.8500\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2545 - accuracy: 0.9125 - val_loss: 0.4955 - val_accuracy: 0.8500\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2474 - accuracy: 0.9187 - val_loss: 0.5116 - val_accuracy: 0.8250\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2556 - accuracy: 0.8875 - val_loss: 0.4962 - val_accuracy: 0.8500\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2508 - accuracy: 0.9187 - val_loss: 0.4965 - val_accuracy: 0.8500\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2465 - accuracy: 0.9125 - val_loss: 0.5005 - val_accuracy: 0.8500\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2443 - accuracy: 0.9250 - val_loss: 0.4982 - val_accuracy: 0.8500\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2458 - accuracy: 0.9187 - val_loss: 0.5069 - val_accuracy: 0.8500\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2424 - accuracy: 0.9187 - val_loss: 0.4982 - val_accuracy: 0.8500\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2412 - accuracy: 0.9250 - val_loss: 0.5024 - val_accuracy: 0.8500\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2424 - accuracy: 0.9062 - val_loss: 0.5074 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2408 - accuracy: 0.9187 - val_loss: 0.5027 - val_accuracy: 0.8500\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2421 - accuracy: 0.9250 - val_loss: 0.5013 - val_accuracy: 0.8500\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2398 - accuracy: 0.9250 - val_loss: 0.5060 - val_accuracy: 0.8500\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2346 - accuracy: 0.9187 - val_loss: 0.5048 - val_accuracy: 0.8500\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2395 - accuracy: 0.9000 - val_loss: 0.5135 - val_accuracy: 0.8500\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2370 - accuracy: 0.9062 - val_loss: 0.5032 - val_accuracy: 0.8250\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2329 - accuracy: 0.9250 - val_loss: 0.5100 - val_accuracy: 0.8500\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2337 - accuracy: 0.9000 - val_loss: 0.5048 - val_accuracy: 0.8500\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2304 - accuracy: 0.9250 - val_loss: 0.5068 - val_accuracy: 0.8500\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2322 - accuracy: 0.9062 - val_loss: 0.5062 - val_accuracy: 0.8500\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2286 - accuracy: 0.9312 - val_loss: 0.5053 - val_accuracy: 0.8500\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2308 - accuracy: 0.9187 - val_loss: 0.5108 - val_accuracy: 0.8500\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2277 - accuracy: 0.9250 - val_loss: 0.5088 - val_accuracy: 0.8500\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2292 - accuracy: 0.9000 - val_loss: 0.5160 - val_accuracy: 0.8500\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2230 - accuracy: 0.9250 - val_loss: 0.5087 - val_accuracy: 0.8500\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2243 - accuracy: 0.9187 - val_loss: 0.5119 - val_accuracy: 0.8500\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2293 - accuracy: 0.8938 - val_loss: 0.5240 - val_accuracy: 0.8500\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2229 - accuracy: 0.9187 - val_loss: 0.5078 - val_accuracy: 0.8250\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2288 - accuracy: 0.9062 - val_loss: 0.5340 - val_accuracy: 0.8500\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2232 - accuracy: 0.9062 - val_loss: 0.5196 - val_accuracy: 0.8500\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2182 - accuracy: 0.9250 - val_loss: 0.5156 - val_accuracy: 0.8500\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2196 - accuracy: 0.9250 - val_loss: 0.5156 - val_accuracy: 0.8500\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2146 - accuracy: 0.9250 - val_loss: 0.5303 - val_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2283 - accuracy: 0.9062 - val_loss: 0.5148 - val_accuracy: 0.8250\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2140 - accuracy: 0.9250 - val_loss: 0.5236 - val_accuracy: 0.8500\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2163 - accuracy: 0.9250 - val_loss: 0.5264 - val_accuracy: 0.8500\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2118 - accuracy: 0.9250 - val_loss: 0.5194 - val_accuracy: 0.8500\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2163 - accuracy: 0.9312 - val_loss: 0.5262 - val_accuracy: 0.8500\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2137 - accuracy: 0.9312 - val_loss: 0.5237 - val_accuracy: 0.8500\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2112 - accuracy: 0.9312 - val_loss: 0.5272 - val_accuracy: 0.8500\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2099 - accuracy: 0.9375 - val_loss: 0.5201 - val_accuracy: 0.8250\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2077 - accuracy: 0.9250 - val_loss: 0.5325 - val_accuracy: 0.8500\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2080 - accuracy: 0.9375 - val_loss: 0.5240 - val_accuracy: 0.8500\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2061 - accuracy: 0.9312 - val_loss: 0.5267 - val_accuracy: 0.8500\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2042 - accuracy: 0.9312 - val_loss: 0.5315 - val_accuracy: 0.8500\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2054 - accuracy: 0.9187 - val_loss: 0.5273 - val_accuracy: 0.8500\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2067 - accuracy: 0.9250 - val_loss: 0.5331 - val_accuracy: 0.8500\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2018 - accuracy: 0.9250 - val_loss: 0.5353 - val_accuracy: 0.8500\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2024 - accuracy: 0.9312 - val_loss: 0.5297 - val_accuracy: 0.8500\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1999 - accuracy: 0.9312 - val_loss: 0.5341 - val_accuracy: 0.8500\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2016 - accuracy: 0.9187 - val_loss: 0.5377 - val_accuracy: 0.8500\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2030 - accuracy: 0.9250 - val_loss: 0.5295 - val_accuracy: 0.8250\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1983 - accuracy: 0.9688 - val_loss: 0.5474 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2017 - accuracy: 0.9250 - val_loss: 0.5402 - val_accuracy: 0.8500\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1978 - accuracy: 0.9312 - val_loss: 0.5315 - val_accuracy: 0.8500\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2054 - accuracy: 0.9438 - val_loss: 0.5365 - val_accuracy: 0.8500\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2109 - accuracy: 0.9125 - val_loss: 0.5657 - val_accuracy: 0.8750\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2005 - accuracy: 0.9438 - val_loss: 0.5392 - val_accuracy: 0.8250\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2026 - accuracy: 0.9500 - val_loss: 0.5557 - val_accuracy: 0.8750\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1983 - accuracy: 0.9250 - val_loss: 0.5383 - val_accuracy: 0.8250\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1937 - accuracy: 0.9438 - val_loss: 0.5451 - val_accuracy: 0.8500\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1922 - accuracy: 0.9312 - val_loss: 0.5448 - val_accuracy: 0.8500\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1951 - accuracy: 0.9500 - val_loss: 0.5471 - val_accuracy: 0.8500\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2030 - accuracy: 0.9125 - val_loss: 0.5483 - val_accuracy: 0.8500\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.2086 - accuracy: 0.9500 - val_loss: 0.5399 - val_accuracy: 0.8000\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2061 - accuracy: 0.9125 - val_loss: 0.5856 - val_accuracy: 0.8500\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1897 - accuracy: 0.9312 - val_loss: 0.5392 - val_accuracy: 0.8000\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.2079 - accuracy: 0.9563 - val_loss: 0.5431 - val_accuracy: 0.8000\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1888 - accuracy: 0.9375 - val_loss: 0.5735 - val_accuracy: 0.8750\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1999 - accuracy: 0.9312 - val_loss: 0.5449 - val_accuracy: 0.8000\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1879 - accuracy: 0.9688 - val_loss: 0.5548 - val_accuracy: 0.8500\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1868 - accuracy: 0.9312 - val_loss: 0.5672 - val_accuracy: 0.8750\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1849 - accuracy: 0.9250 - val_loss: 0.5513 - val_accuracy: 0.8000\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1874 - accuracy: 0.9625 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1864 - accuracy: 0.9312 - val_loss: 0.5722 - val_accuracy: 0.8750\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1828 - accuracy: 0.9438 - val_loss: 0.5513 - val_accuracy: 0.8000\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1823 - accuracy: 0.9500 - val_loss: 0.5604 - val_accuracy: 0.8250\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1898 - accuracy: 0.9312 - val_loss: 0.5697 - val_accuracy: 0.8750\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1829 - accuracy: 0.9688 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1807 - accuracy: 0.9688 - val_loss: 0.5712 - val_accuracy: 0.8500\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1886 - accuracy: 0.9125 - val_loss: 0.5693 - val_accuracy: 0.8500\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1779 - accuracy: 0.9688 - val_loss: 0.5592 - val_accuracy: 0.8000\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1788 - accuracy: 0.9500 - val_loss: 0.5658 - val_accuracy: 0.8250\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1764 - accuracy: 0.9625 - val_loss: 0.5629 - val_accuracy: 0.8000\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1785 - accuracy: 0.9438 - val_loss: 0.5732 - val_accuracy: 0.8250\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1777 - accuracy: 0.9438 - val_loss: 0.5613 - val_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1754 - accuracy: 0.9625 - val_loss: 0.5827 - val_accuracy: 0.8750\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1788 - accuracy: 0.9250 - val_loss: 0.5705 - val_accuracy: 0.8250\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1767 - accuracy: 0.9563 - val_loss: 0.5660 - val_accuracy: 0.8000\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1725 - accuracy: 0.9625 - val_loss: 0.5765 - val_accuracy: 0.8250\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1746 - accuracy: 0.9312 - val_loss: 0.5729 - val_accuracy: 0.8250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conv1D Double Layer"
      ],
      "metadata": {
        "id": "B5pVa9bXo0tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential([\n",
        "    Input(shape=(timesteps, features), batch_size=1),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "    Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
        "\n",
        "    MaxPooling1D(),\n",
        "    Flatten(),\n",
        "    Dense(output_units, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rkqdjfXXlJgk",
        "outputId": "b7f2d3b4-98ed-483b-b135-e843989ab8ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 75ms/step - loss: 0.6986 - accuracy: 0.5125 - val_loss: 0.6857 - val_accuracy: 0.7000\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6876 - accuracy: 0.5750 - val_loss: 0.6840 - val_accuracy: 0.5750\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.6817 - accuracy: 0.6250 - val_loss: 0.6775 - val_accuracy: 0.7500\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6773 - accuracy: 0.5750 - val_loss: 0.6745 - val_accuracy: 0.5750\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6659 - accuracy: 0.7000 - val_loss: 0.6679 - val_accuracy: 0.7250\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.6568 - accuracy: 0.7063 - val_loss: 0.6617 - val_accuracy: 0.5250\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6484 - accuracy: 0.6625 - val_loss: 0.6479 - val_accuracy: 0.7250\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.6311 - accuracy: 0.6875 - val_loss: 0.6457 - val_accuracy: 0.5250\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6162 - accuracy: 0.7125 - val_loss: 0.6243 - val_accuracy: 0.7500\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5886 - accuracy: 0.7563 - val_loss: 0.6160 - val_accuracy: 0.6250\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5689 - accuracy: 0.7500 - val_loss: 0.6031 - val_accuracy: 0.7000\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.5490 - accuracy: 0.7250 - val_loss: 0.5880 - val_accuracy: 0.7000\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.5324 - accuracy: 0.7312 - val_loss: 0.5783 - val_accuracy: 0.7500\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5083 - accuracy: 0.7750 - val_loss: 0.5711 - val_accuracy: 0.7750\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4979 - accuracy: 0.7375 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4760 - accuracy: 0.8000 - val_loss: 0.5402 - val_accuracy: 0.7750\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4792 - accuracy: 0.7563 - val_loss: 0.5443 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4932 - accuracy: 0.7063 - val_loss: 0.5304 - val_accuracy: 0.7750\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.4641 - accuracy: 0.7688 - val_loss: 0.5281 - val_accuracy: 0.7750\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4509 - accuracy: 0.7937 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4366 - accuracy: 0.8000 - val_loss: 0.5152 - val_accuracy: 0.7250\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4240 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7250\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4208 - accuracy: 0.8125 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4127 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7250\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4114 - accuracy: 0.7875 - val_loss: 0.4862 - val_accuracy: 0.7750\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.4033 - accuracy: 0.7812 - val_loss: 0.5007 - val_accuracy: 0.7250\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4110 - accuracy: 0.7625 - val_loss: 0.4870 - val_accuracy: 0.8000\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3830 - accuracy: 0.8062 - val_loss: 0.4858 - val_accuracy: 0.7250\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3918 - accuracy: 0.8000 - val_loss: 0.4766 - val_accuracy: 0.7500\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.3846 - accuracy: 0.8062 - val_loss: 0.4816 - val_accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3983 - accuracy: 0.7688 - val_loss: 0.4827 - val_accuracy: 0.8250\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.3956 - accuracy: 0.7937 - val_loss: 0.4637 - val_accuracy: 0.7750\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3740 - accuracy: 0.8125 - val_loss: 0.4667 - val_accuracy: 0.7750\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.3633 - accuracy: 0.8375 - val_loss: 0.4691 - val_accuracy: 0.8250\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3553 - accuracy: 0.8438 - val_loss: 0.4681 - val_accuracy: 0.7750\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3571 - accuracy: 0.8375 - val_loss: 0.4693 - val_accuracy: 0.7750\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3463 - accuracy: 0.8500 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3464 - accuracy: 0.8500 - val_loss: 0.4769 - val_accuracy: 0.8000\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3341 - accuracy: 0.8687 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.3395 - accuracy: 0.8438 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.3321 - accuracy: 0.8687 - val_loss: 0.4657 - val_accuracy: 0.8000\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3326 - accuracy: 0.8438 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3286 - accuracy: 0.8438 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3248 - accuracy: 0.8500 - val_loss: 0.4700 - val_accuracy: 0.7750\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3342 - accuracy: 0.8438 - val_loss: 0.4768 - val_accuracy: 0.8250\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3062 - accuracy: 0.8750 - val_loss: 0.4679 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3307 - accuracy: 0.8250 - val_loss: 0.4857 - val_accuracy: 0.8250\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.3142 - accuracy: 0.8500 - val_loss: 0.4659 - val_accuracy: 0.8250\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.3035 - accuracy: 0.8750 - val_loss: 0.4648 - val_accuracy: 0.8250\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2975 - accuracy: 0.8813 - val_loss: 0.4732 - val_accuracy: 0.8250\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2956 - accuracy: 0.8687 - val_loss: 0.4705 - val_accuracy: 0.8250\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2951 - accuracy: 0.8875 - val_loss: 0.4693 - val_accuracy: 0.8250\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.3212 - accuracy: 0.8438 - val_loss: 0.4761 - val_accuracy: 0.8250\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.3111 - accuracy: 0.8375 - val_loss: 0.4951 - val_accuracy: 0.8250\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2955 - accuracy: 0.8875 - val_loss: 0.4763 - val_accuracy: 0.8000\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.3004 - accuracy: 0.8625 - val_loss: 0.4793 - val_accuracy: 0.8250\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2841 - accuracy: 0.8687 - val_loss: 0.4814 - val_accuracy: 0.8000\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2791 - accuracy: 0.8938 - val_loss: 0.4902 - val_accuracy: 0.8500\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2834 - accuracy: 0.8750 - val_loss: 0.4820 - val_accuracy: 0.8250\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2776 - accuracy: 0.8875 - val_loss: 0.4796 - val_accuracy: 0.8250\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2738 - accuracy: 0.8813 - val_loss: 0.4900 - val_accuracy: 0.8250\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.2659 - accuracy: 0.9062 - val_loss: 0.4899 - val_accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2735 - accuracy: 0.8687 - val_loss: 0.5000 - val_accuracy: 0.8250\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2802 - accuracy: 0.8750 - val_loss: 0.4988 - val_accuracy: 0.8250\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.2617 - accuracy: 0.9187 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2605 - accuracy: 0.8938 - val_loss: 0.5142 - val_accuracy: 0.8500\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2681 - accuracy: 0.8750 - val_loss: 0.5082 - val_accuracy: 0.7750\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2767 - accuracy: 0.8687 - val_loss: 0.4976 - val_accuracy: 0.8250\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2522 - accuracy: 0.9125 - val_loss: 0.5096 - val_accuracy: 0.8250\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2538 - accuracy: 0.9125 - val_loss: 0.4982 - val_accuracy: 0.8250\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2687 - accuracy: 0.8438 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2634 - accuracy: 0.8813 - val_loss: 0.5299 - val_accuracy: 0.8500\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2514 - accuracy: 0.9125 - val_loss: 0.5118 - val_accuracy: 0.7750\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2526 - accuracy: 0.9062 - val_loss: 0.5260 - val_accuracy: 0.8500\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2471 - accuracy: 0.9000 - val_loss: 0.5164 - val_accuracy: 0.8250\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2507 - accuracy: 0.8938 - val_loss: 0.5241 - val_accuracy: 0.8500\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.2411 - accuracy: 0.9125 - val_loss: 0.5242 - val_accuracy: 0.8250\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2364 - accuracy: 0.9000 - val_loss: 0.5156 - val_accuracy: 0.8000\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.2404 - accuracy: 0.9000 - val_loss: 0.5303 - val_accuracy: 0.8250\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2446 - accuracy: 0.9062 - val_loss: 0.5223 - val_accuracy: 0.7750\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2410 - accuracy: 0.9125 - val_loss: 0.5338 - val_accuracy: 0.8500\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.2308 - accuracy: 0.9250 - val_loss: 0.5218 - val_accuracy: 0.7750\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2324 - accuracy: 0.9187 - val_loss: 0.5325 - val_accuracy: 0.8000\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.2310 - accuracy: 0.9062 - val_loss: 0.5291 - val_accuracy: 0.7750\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.2266 - accuracy: 0.9187 - val_loss: 0.5329 - val_accuracy: 0.8250\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.2223 - accuracy: 0.9062 - val_loss: 0.5349 - val_accuracy: 0.8250\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2232 - accuracy: 0.9125 - val_loss: 0.5415 - val_accuracy: 0.8250\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.2268 - accuracy: 0.9250 - val_loss: 0.5508 - val_accuracy: 0.8500\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2303 - accuracy: 0.9000 - val_loss: 0.5457 - val_accuracy: 0.8000\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.2195 - accuracy: 0.9125 - val_loss: 0.5533 - val_accuracy: 0.8000\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2218 - accuracy: 0.9125 - val_loss: 0.5547 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2126 - accuracy: 0.9312 - val_loss: 0.5447 - val_accuracy: 0.8250\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.2169 - accuracy: 0.9000 - val_loss: 0.5573 - val_accuracy: 0.8000\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 0.2189 - accuracy: 0.9062 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.2079 - accuracy: 0.9250 - val_loss: 0.5423 - val_accuracy: 0.8250\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2191 - accuracy: 0.9125 - val_loss: 0.5660 - val_accuracy: 0.8500\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2018 - accuracy: 0.9312 - val_loss: 0.5574 - val_accuracy: 0.8250\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2089 - accuracy: 0.9125 - val_loss: 0.5707 - val_accuracy: 0.8500\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2027 - accuracy: 0.9250 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.2046 - accuracy: 0.9125 - val_loss: 0.5623 - val_accuracy: 0.8000\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.1971 - accuracy: 0.9187 - val_loss: 0.5880 - val_accuracy: 0.8500\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.2141 - accuracy: 0.8875 - val_loss: 0.5766 - val_accuracy: 0.8000\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.2064 - accuracy: 0.9062 - val_loss: 0.5949 - val_accuracy: 0.8500\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.2215 - accuracy: 0.9062 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.2184 - accuracy: 0.9187 - val_loss: 0.5776 - val_accuracy: 0.8000\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.2133 - accuracy: 0.9125 - val_loss: 0.6164 - val_accuracy: 0.8500\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.1912 - accuracy: 0.9250 - val_loss: 0.5843 - val_accuracy: 0.7750\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 46ms/step - loss: 0.2116 - accuracy: 0.9187 - val_loss: 0.5906 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 48ms/step - loss: 0.1949 - accuracy: 0.9250 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1998 - accuracy: 0.9312 - val_loss: 0.5876 - val_accuracy: 0.8500\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.1886 - accuracy: 0.9187 - val_loss: 0.6150 - val_accuracy: 0.8500\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1889 - accuracy: 0.9375 - val_loss: 0.5801 - val_accuracy: 0.8250\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1977 - accuracy: 0.9250 - val_loss: 0.5999 - val_accuracy: 0.8500\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1872 - accuracy: 0.9312 - val_loss: 0.5820 - val_accuracy: 0.8000\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1856 - accuracy: 0.9187 - val_loss: 0.5882 - val_accuracy: 0.8250\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1782 - accuracy: 0.9250 - val_loss: 0.6017 - val_accuracy: 0.8750\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.1767 - accuracy: 0.9312 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1758 - accuracy: 0.9250 - val_loss: 0.6020 - val_accuracy: 0.8250\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1853 - accuracy: 0.9250 - val_loss: 0.5988 - val_accuracy: 0.8250\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1806 - accuracy: 0.9375 - val_loss: 0.6069 - val_accuracy: 0.8250\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1855 - accuracy: 0.9187 - val_loss: 0.6055 - val_accuracy: 0.8000\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1700 - accuracy: 0.9187 - val_loss: 0.6125 - val_accuracy: 0.8000\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1683 - accuracy: 0.9250 - val_loss: 0.6182 - val_accuracy: 0.8500\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.1697 - accuracy: 0.9312 - val_loss: 0.6243 - val_accuracy: 0.8750\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.1706 - accuracy: 0.9312 - val_loss: 0.6082 - val_accuracy: 0.8000\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.1693 - accuracy: 0.9250 - val_loss: 0.6257 - val_accuracy: 0.8500\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.1670 - accuracy: 0.9500 - val_loss: 0.6205 - val_accuracy: 0.8250\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.1687 - accuracy: 0.9250 - val_loss: 0.6310 - val_accuracy: 0.8250\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 0.1704 - accuracy: 0.9250 - val_loss: 0.6177 - val_accuracy: 0.8250\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.1614 - accuracy: 0.9375 - val_loss: 0.6366 - val_accuracy: 0.8000\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 52ms/step - loss: 0.1649 - accuracy: 0.9312 - val_loss: 0.6358 - val_accuracy: 0.8250\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.1606 - accuracy: 0.9500 - val_loss: 0.6537 - val_accuracy: 0.8750\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.1653 - accuracy: 0.9312 - val_loss: 0.6407 - val_accuracy: 0.8250\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.1600 - accuracy: 0.9500 - val_loss: 0.6420 - val_accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.1530 - accuracy: 0.9625 - val_loss: 0.6626 - val_accuracy: 0.8500\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1539 - accuracy: 0.9250 - val_loss: 0.6442 - val_accuracy: 0.8000\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 50ms/step - loss: 0.1623 - accuracy: 0.9312 - val_loss: 0.6416 - val_accuracy: 0.8000\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 0.1591 - accuracy: 0.9187 - val_loss: 0.6742 - val_accuracy: 0.8500\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 0.1554 - accuracy: 0.9563 - val_loss: 0.6467 - val_accuracy: 0.8250\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.1546 - accuracy: 0.9438 - val_loss: 0.6613 - val_accuracy: 0.8250\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 0.1529 - accuracy: 0.9312 - val_loss: 0.6461 - val_accuracy: 0.8250\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.1440 - accuracy: 0.9375 - val_loss: 0.6928 - val_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1666 - accuracy: 0.9250 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.1495 - accuracy: 0.9500 - val_loss: 0.6721 - val_accuracy: 0.8500\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1561 - accuracy: 0.9375 - val_loss: 0.6814 - val_accuracy: 0.8500\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.1450 - accuracy: 0.9625 - val_loss: 0.6666 - val_accuracy: 0.8000\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.1434 - accuracy: 0.9563 - val_loss: 0.6783 - val_accuracy: 0.8250\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.1467 - accuracy: 0.9438 - val_loss: 0.6581 - val_accuracy: 0.8000\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1406 - accuracy: 0.9500 - val_loss: 0.6749 - val_accuracy: 0.8750\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.1367 - accuracy: 0.9688 - val_loss: 0.6615 - val_accuracy: 0.8000\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.1360 - accuracy: 0.9563 - val_loss: 0.6920 - val_accuracy: 0.8750\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 45ms/step - loss: 0.1348 - accuracy: 0.9563 - val_loss: 0.6889 - val_accuracy: 0.8250\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.1354 - accuracy: 0.9750 - val_loss: 0.6864 - val_accuracy: 0.8250\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1324 - accuracy: 0.9563 - val_loss: 0.6893 - val_accuracy: 0.8500\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.1321 - accuracy: 0.9563 - val_loss: 0.6857 - val_accuracy: 0.8250\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 0.1356 - accuracy: 0.9563 - val_loss: 0.7143 - val_accuracy: 0.8750\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.1309 - accuracy: 0.9625 - val_loss: 0.6915 - val_accuracy: 0.8250\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.1286 - accuracy: 0.9688 - val_loss: 0.7006 - val_accuracy: 0.8250\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1274 - accuracy: 0.9625 - val_loss: 0.7018 - val_accuracy: 0.8250\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1298 - accuracy: 0.9688 - val_loss: 0.7095 - val_accuracy: 0.8000\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1287 - accuracy: 0.9625 - val_loss: 0.6939 - val_accuracy: 0.8000\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1241 - accuracy: 0.9688 - val_loss: 0.7407 - val_accuracy: 0.8750\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1332 - accuracy: 0.9500 - val_loss: 0.7144 - val_accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1283 - accuracy: 0.9688 - val_loss: 0.7090 - val_accuracy: 0.8250\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1347 - accuracy: 0.9688 - val_loss: 0.7106 - val_accuracy: 0.8250\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.7454 - val_accuracy: 0.8750\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.1311 - accuracy: 0.9625 - val_loss: 0.7044 - val_accuracy: 0.8000\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1254 - accuracy: 0.9750 - val_loss: 0.7570 - val_accuracy: 0.8750\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1249 - accuracy: 0.9563 - val_loss: 0.6967 - val_accuracy: 0.8000\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1294 - accuracy: 0.9438 - val_loss: 0.7262 - val_accuracy: 0.8750\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1145 - accuracy: 0.9812 - val_loss: 0.7105 - val_accuracy: 0.8000\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1230 - accuracy: 0.9750 - val_loss: 0.7694 - val_accuracy: 0.8500\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1235 - accuracy: 0.9563 - val_loss: 0.7140 - val_accuracy: 0.8000\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1376 - accuracy: 0.9563 - val_loss: 0.7199 - val_accuracy: 0.8000\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1481 - accuracy: 0.9438 - val_loss: 0.7740 - val_accuracy: 0.8750\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1184 - accuracy: 0.9812 - val_loss: 0.7034 - val_accuracy: 0.8000\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1299 - accuracy: 0.9500 - val_loss: 0.7578 - val_accuracy: 0.8500\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1230 - accuracy: 0.9625 - val_loss: 0.7370 - val_accuracy: 0.8500\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 0.7214 - val_accuracy: 0.8250\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1124 - accuracy: 0.9688 - val_loss: 0.7429 - val_accuracy: 0.8500\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1186 - accuracy: 0.9750 - val_loss: 0.7273 - val_accuracy: 0.8250\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1098 - accuracy: 0.9750 - val_loss: 0.7414 - val_accuracy: 0.8250\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1232 - accuracy: 0.9688 - val_loss: 0.7355 - val_accuracy: 0.8000\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1243 - accuracy: 0.9625 - val_loss: 0.7784 - val_accuracy: 0.8500\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1119 - accuracy: 0.9688 - val_loss: 0.7330 - val_accuracy: 0.8000\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1111 - accuracy: 0.9750 - val_loss: 0.7812 - val_accuracy: 0.8500\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1082 - accuracy: 0.9812 - val_loss: 0.7483 - val_accuracy: 0.8000\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.1120 - accuracy: 0.9688 - val_loss: 0.7552 - val_accuracy: 0.8000\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.1022 - accuracy: 0.9875 - val_loss: 0.7827 - val_accuracy: 0.8750\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1070 - accuracy: 0.9688 - val_loss: 0.7621 - val_accuracy: 0.8000\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1029 - accuracy: 0.9812 - val_loss: 0.7812 - val_accuracy: 0.8750\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0981 - accuracy: 0.9875 - val_loss: 0.7458 - val_accuracy: 0.8000\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.1002 - accuracy: 0.9875 - val_loss: 0.7774 - val_accuracy: 0.8500\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1022 - accuracy: 0.9875 - val_loss: 0.7873 - val_accuracy: 0.8500\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1036 - accuracy: 0.9750 - val_loss: 0.7533 - val_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0956 - accuracy: 0.9750 - val_loss: 0.8283 - val_accuracy: 0.8500\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.1065 - accuracy: 0.9625 - val_loss: 0.7601 - val_accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.0974 - accuracy: 0.9750 - val_loss: 0.7673 - val_accuracy: 0.8250\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0948 - accuracy: 0.9812 - val_loss: 0.7919 - val_accuracy: 0.8500\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0924 - accuracy: 0.9812 - val_loss: 0.7666 - val_accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verify"
      ],
      "metadata": {
        "id": "V9_zYZlrw-74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Graph Loss Skipping Start"
      ],
      "metadata": {
        "id": "5ISqP4y0xJuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run with Test Data"
      ],
      "metadata": {
        "id": "XcVGP6ZgxZ4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model to predict the test inputs\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to actual class predictions:\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "# Convert one-hot encoded y_test to class labels\n",
        "actual_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(actual_classes, predicted_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(predicted_classes == actual_classes)\n",
        "print(f'Model accuracy on the test dataset: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "iv8T0U-Rxc94",
        "outputId": "387364c7-a2ba-4fa4-a8eb-4131ac80ba94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on the test dataset: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test on Whole Dataset"
      ],
      "metadata": {
        "id": "OAU4NaJO4KZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on ALL DATA\n",
        "predictions = model.predict(X)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "actual_classes = np.argmax(y, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(actual_classes, predicted_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(predicted_classes == actual_classes)\n",
        "print(f'Model accuracy on the full dataset: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "8cQ1yPtC3cdH",
        "outputId": "a727e3c0-3ed1-4766-a8fb-2821ec4a1479"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on the full dataset: 95.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert to TFLite"
      ],
      "metadata": {
        "id": "IRNExCFBxeQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the model to TensorFlow Lite format for deployment\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Define a generator function that provides the test data.\n",
        "def representative_dataset_gen():\n",
        "    for i in range(len(X_test)):\n",
        "        # Get sample input data as a numpy array\n",
        "        yield [X_test[i:i+1].astype(np.float32)]\n",
        "\n",
        "# Set the representative dataset for quantization.\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to a file\n",
        "with open('shot_classification.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "5y8IDUK2vhpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8eb54bf-2696-400b-919b-58f802b1172a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test TFLite Model"
      ],
      "metadata": {
        "id": "Cbv2C_xSGaqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/shot_classification.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "predicted_labels = []\n",
        "actual_labels = []\n",
        "\n",
        "# Loop through each item in X to make predictions\n",
        "for i in range(len(X)):\n",
        "    test_example = np.expand_dims(X[i], axis=0)  # Add batch dimension\n",
        "    interpreter.set_tensor(input_details[0]['index'], test_example)\n",
        "    interpreter.invoke()  # Run the model\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predicted_label = np.argmax(output_data)  # Get the predicted label\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "    # Get the actual label from y\n",
        "    actual_label = np.argmax(y[i])\n",
        "    actual_labels.append(actual_label)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(np.array(predicted_labels) == np.array(actual_labels))\n",
        "print(f'Model accuracy on the whole dataset: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "6qR9CBdoGZ74",
        "outputId": "5c413c29-b8d6-465f-e860-ee5a0077cde5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy on the whole dataset: 95.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encode to C"
      ],
      "metadata": {
        "id": "M3i7LCIaxlGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert some hex calue into an array for C program\n",
        "def hex_to_c_array(hex_data, var_name):\n",
        "\n",
        "  c_str = ''\n",
        "\n",
        "  # Create header guard\n",
        "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
        "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
        "\n",
        "  # Add array length at top of file\n",
        "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
        "\n",
        "  # Declare C variable\n",
        "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
        "  hex_array = []\n",
        "  for i, val in enumerate(hex_data) :\n",
        "\n",
        "    # Construct string from hex\n",
        "    hex_str = format(val, '#04x')\n",
        "\n",
        "    # Add formatting so each line stays within 80 characters\n",
        "    if (i + 1) < len(hex_data):\n",
        "      hex_str += ','\n",
        "    if (i + 1) % 12 == 0:\n",
        "      hex_str += '\\n '\n",
        "    hex_array.append(hex_str)\n",
        "\n",
        "  # Add closing brace\n",
        "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
        "\n",
        "  # Close out header guard\n",
        "  c_str += '#endif //' + var_name.upper() + '_H'\n",
        "\n",
        "  return c_str"
      ],
      "metadata": {
        "id": "bvZrc2mLxnd6"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# write TFLite model to C source file\n",
        "with open(\"tflite_model.h\", 'w') as file:\n",
        "    file.write(hex_to_c_array(tflite_model, \"tflite_model\"))\n",
        "\n",
        "# Get the size of the TFLite model in bytes.\n",
        "model_size = os.path.getsize(\"tflite_model.h\")\n",
        "print(f'Model size: {model_size/1024} KB')"
      ],
      "metadata": {
        "id": "HKhMApC7QUTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8a1ff8-d792-4059-bc83-4a58078cda25"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 118.8994140625 KB\n"
          ]
        }
      ]
    }
  ]
}